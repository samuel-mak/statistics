<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Catgorical outcomes | others</title>
  <meta name="description" content="Chapter 7 Catgorical outcomes | others" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Catgorical outcomes | others" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Catgorical outcomes | others" />
  
  
  

<meta name="author" content="Samuel Mak" />


<meta name="date" content="2022-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multivariate-analysis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a >Section</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> The Linear Regression Model</a></li>
<li class="chapter" data-level="2" data-path="generalised-least-squares.html"><a href="generalised-least-squares.html"><i class="fa fa-check"></i><b>2</b> Generalised Least Squares</a></li>
<li class="chapter" data-level="3" data-path="mathematics.html"><a href="mathematics.html"><i class="fa fa-check"></i><b>3</b> Mathematics</a></li>
<li class="chapter" data-level="4" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>4</b> ANOVA</a></li>
<li class="chapter" data-level="5" data-path="derivation.html"><a href="derivation.html"><i class="fa fa-check"></i><b>5</b> Derivation</a></li>
<li class="chapter" data-level="6" data-path="multivariate-analysis.html"><a href="multivariate-analysis.html"><i class="fa fa-check"></i><b>6</b> Multivariate Analysis</a></li>
<li class="chapter" data-level="7" data-path="catgorical-outcomes.html"><a href="catgorical-outcomes.html"><i class="fa fa-check"></i><b>7</b> Catgorical outcomes</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">others</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="catgorical-outcomes" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Catgorical outcomes<a href="catgorical-outcomes.html#catgorical-outcomes" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>Analysing Categorical Outcomes</strong>
</p>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The process of analysing categorical outcomes</li>
</ul></li>
<li><strong>Statistics</strong>
<ul>
<li>Binomial test</li>
<li>Pearson’s Chi-squared</li>
<li>Cochran-Mantel-Haenszel Chi-squared test</li>
<li>McNemar’s test</li>
<li>Fisher’s Exact Test</li>
<li>Barnard’s exact test</li>
<li>Boschloo’s test</li>
<li>G-test</li>
<li>Cramér’s V</li>
</ul></li>
<li><strong>Pearson’s Chi-squared test (Pearson, 1900)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A statistical test that tests the null hypothesis that 2 categorical variables are independent</li>
<li>Test of independence between 2 categorical variable is like a test of homogeneity of conditional distributions
<ul>
<li>For example, if factor A and factor B are independent, then the conditional probabilities are homogeneous (<span class="math inline">\(P(\text{Married once} | \text{College}) = P( \text{Married once}| \text{No College})\)</span>)</li>
</ul></li>
<li><strong>Conceptual Hypotheses</strong>
<ul>
<li><strong>Null Hypothesis</strong>
<ul>
<li>The two categorical variables are independent</li>
</ul></li>
<li><strong>Alternative Hypothesis</strong>
<ul>
<li>The two categorical variables are not independent (they are associated)</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The probability of each cell under the null hypothesis</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The probability of each joint-category under the null hypothesis</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\pi_{ij} = \pi_{i\cdot} \pi_{\cdot j}\)</span></li>
</ul></li>
<li><strong>Estimation</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The maximum likelihood estimation of the population probability of each of the joint-categories</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \hat{\pi}_{ij} = \hat\pi_{i\cdot} \hat\pi_{\cdot j} = \frac{n_{i \cdot}}{n} \times \frac{n_{\cdot j}}{n} = \frac{n_{i \cdot} n_{\cdot j}}{n^2}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(n_{i\cdot}\)</span> - The number of observations in the <span class="math inline">\(i\)</span><sup>th</sup> row</li>
<li><span class="math inline">\(n_{\cdot j}\)</span> - The number of observations in the <span class="math inline">\(j\)</span><sup>th</sup> column</li>
<li><span class="math inline">\(n\)</span> - The total sample size</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The expected number of observations</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The number of observations in each of the K joint-categories under the null hypothesis that the 2 categorical variables are independent</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle E(n_{ij}) = n\hat{\pi}_{ij} = n\frac{n_{i \cdot} n_{\cdot j}}{n^2} = \frac{n_{i \cdot} n_{\cdot j}}{n}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Pearson’s Chi-squared statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The sum of the standardised squared deviations of the observed number of observations and the expected number of observations under the null hypothesis of each of the K joint-categories</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \chi^2 &amp;= \sum_{i = 1}^{I}{\sum_{j = 1}^{J}{\frac{\left[ n_{ij} - E(n_{ij})\right]^2}{E(n_{ij})}}} \\ \displaystyle &amp;= \sum_{i = 1}^{I}{\sum_{j = 1}^{J}{\frac{\left( n_{ij} - \frac{n_{i\cdot} n_{\cdot j}}{n}\right)^2}{\frac{n_{i\cdot} n_{\cdot j}}{n}}}} \end{aligned}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(n_{ij}\)</span> - The observed number of observations in joint-category <span class="math inline">\(ij\)</span></li>
<li><span class="math inline">\(E(n_{jk}\)</span> - The expected number of observations in joint-category <span class="math inline">\(ij\)</span> under the null hypothesis</li>
<li><span class="math inline">\(\left( n_{ij} - \frac{n_{i\cdot} n_{\cdot j}}{n}\right)^2\)</span> - The squared deviation for for joint-category <span class="math inline">\(ij\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Degrees of freedom (NOT ENTIRELY SURE)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The degrees of freedom under the null hypothesis is the number of joint-categories minus the number of independent linear restrictions placed on the cell probabilities</li>
<li>Although the calculation of the number of degrees of freedom depends on the application of the Chi-squared test, the general principle is that the appropriate number of degrees of freedom will equal the number of joint-categories minus 1 df for each independent linear restriction placed on the cell probabilities. In some applications, other restrictions may also be introduced because of the necessity for estimating unkown parameters required in the calculation of the expected cell frequencies or because of the method used to collect the sample</li>
<li>There is always one linear restriction in each cell because the sum of the cell probabilities must equal 1 (<span class="math inline">\(p_1 + p_2 + p_3 + \cdots + p_k = 1\)</span>)</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(df = IJ - 1 - (I-1) - (J-1) = (I-1)(J-1)\)</span>
<ul>
<li><strong><em>Note</em></strong>
<ul>
<li>The equation shows that df is the total number of joint-categories (<span class="math inline">\(IJ\)</span>) minus the number of restrictions in the <span class="math inline">\(I\)</span> rows, minus the number of restrictions in the <span class="math inline">\(J\)</span> columns, and minus the number of restrictions in all the cells as a whole (minus the 1) (NOT ENTIRELY SURE)</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Introduction</strong>
<ul>
<li>The calculation of the number of degrees of freedom depends on the application of the Chi-squared test</li>
<li>The general principle is that the appropriate number of degrees of freedom will equal the number of cells, k, less 1 df for each independent linear restriction placed on the cell probabilities</li>
<li>There is always one linear restriction in each cell because the sum of the cell probabilities must equal 1 (<span class="math inline">\(p_1 + p_2 + p_3 + \cdots + p_k = 1\)</span>)</li>
</ul></li>
</ul></li>
<li><strong>Distribution of the Chi-squared statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li><span class="math inline">\(X^2\)</span> tends towards a chi-squared distribution as n increases (it can be shown)</li>
<li>The square root of the chi-squared statistic is a normal random variable (normally distributed)</li>
<li>The square of a normal random variable has a chi-squared distribution</li>
<li>Hence, the chi-squared statistic has a chi-square distribution</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(X^2 \sim \chi\)</span></li>
</ul></li>
</ul></li>
<li><strong>NHST</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Tests the probability of having a Chi-squared statistic equal to or larger than the observed Chi-squared statistic in the Chi-square distribution under the null hypothesis</li>
</ul></li>
<li><strong>Hypotheses</strong>
<ul>
<li><span class="math inline">\(H_0: \pi_{ij} = \pi_{i \cdot}\pi_{\cdot j}, ~~~~~ \text{for} ~ i = 1:I, j = 1:J\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Some caveats</strong>
<ul>
<li><strong>Number of cell counts</strong>
<ul>
<li>There is a rule of thumb that it is all expected cell counts are required to be at least 5.</li>
<li>Although Cochran (1952) noted that his can be as low as one for some situations</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Odds Ratio</strong>
<ul>
<li><strong>Odds</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The ratio of the probability of an event occurring to the probability of the event not occurring</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle Odds(\text{event}) = \frac{P(\text{event})}{1 - P(\text{event})}\)</span></li>
</ul></li>
<li><strong>Conditional Odds</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The ratio of the probability of an event occurring given a value/level of another categorical variable to the probability of it not occurring</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle Odds(A | x) = \frac{P(A | x)}{1 - (A | x)}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The Odds Ratio</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The ratio of the odds of an event given a value of a categorical variable and the odds of the same event given another value of the same categorical variable</li>
<li>This ratio tells the influence of the level of the second categorical variable in the numerator have on the probability of the event of interest</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle OR(A) = \frac{Odds(A|x_1)}{Odds{(A|x_2)}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Bernoulli Trails</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A Bernoulli trial is a random independent experiment with 2 possible outcomes (usually referred to as “success” or “failure”) and the probability of the “success” event (<span class="math inline">\(\pi\)</span>) is the same every time the experiment is conducted (identical trials) and the outcome of each of the trials does not influence the outcome of other trials (independent trials; sampling with replacement)</li>
<li><span class="math inline">\(y_i\)</span> - The outcome of Bernoulli trial <span class="math inline">\(i\)</span> in the sequence of <span class="math inline">\(n\)</span> trials - 1 indicates that the “success” event had occurred and 0 indicates that the “failure” event had occurred in trial <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(y\)</span> - The total number of “success” events in a sequence of <span class="math inline">\(n\)</span> trials - <span class="math inline">\(y = \sum_{i = 1}^{n}{y_i}\)</span></li>
<li><span class="math inline">\(y\)</span> is treated as an independent random variable that can vary between the 2 possible outcomes (the “success” event or the “failure” event)</li>
<li>Bernoulli process - When there is a sequence of Bernoulli trials</li>
<li><span class="math inline">\(p= 1-q\)</span></li>
<li><span class="math inline">\(p\)</span> - The probability of event occurring</li>
<li><span class="math inline">\(q\)</span> - The probability of the event not occurring</li>
</ul></li>
</ul></li>
</ul>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>Binomial Distribution</strong>
</p>
<ul>
<li><strong>Binomial Distribution</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A special case of the multinomial distribution when the number of trials <span class="math inline">\(K = 2\)</span></li>
<li>A discrete probability distribution for the discrete independent random variable (<span class="math inline">\(y\)</span>) of the number of the “success” events in a sequence of a fixed/finite <span class="math inline">\(n\)</span> number of Bernoulli trials/experiments (independent, identical) (the x-axis represents the number of successes; the y-axis represents the probability)</li>
<li>(if trials are not independent or identical, <span class="math inline">\(y\)</span> will not follow a binomial distribution, they will follow other distributions; e.g. hypergeometric distribution is for the case when trials are not independent; specifically, it samples without replacement)</li>
<li>A Bernoulli distribution is a special case of the binomial distribution where <span class="math inline">\(n = 1\)</span></li>
<li>The binomial distribution has 2 parameters, <span class="math inline">\(n\)</span>, the number of Bernoulli experiments in the sequence, and <span class="math inline">\(\pi\)</span>, the probability of each of the numbers of “success” events</li>
<li>An independent random variable (<span class="math inline">\(y\)</span>) that has an approximate binomial distribution is denoted as <span class="math inline">\(y \sim B(n, \pi)\)</span></li>
</ul></li>
<li><strong>Binomial probability mass function</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The probability mass function for the binomial distribution</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(P(y) = {n\choose y} \pi^y (1 - \pi)^{n - y} ~~~, y = 0:n\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li><span class="math inline">\({n\choose y}\)</span> - The binomial coefficient</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Parameters of the binomial distribution</strong>
<ul>
<li><strong>Mean</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\mu = \text{E}(y) = n\pi\)</span></li>
</ul></li>
</ul></li>
<li><strong>Variance</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\sigma^2 = n\pi(1-\pi)\)</span></li>
</ul></li>
</ul></li>
<li><strong>Characteristics of the binomial distribution</strong>
<ul>
<li><strong><span class="math inline">\(\pi\)</span> and Skewness (biasedness)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The binomial is symmetric when <span class="math inline">\(\pi = 0.50\)</span> regardless of <span class="math inline">\(n\)</span></li>
<li>The binomial distribution becomes more positively skewed as <span class="math inline">\(\pi\)</span> decreases from <span class="math inline">\(0.50\)</span> towards 0</li>
<li>The binomial distribution becomes more negatively skewed as <span class="math inline">\(\pi\)</span> increases from <span class="math inline">\(0.50\)</span> towards 1</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li>The skewness is described by the following equality:</li>
<li><span class="math inline">\(\displaystyle \frac{\text{E}(y-\mu)^3}{\sigma^3} = \frac{1-2\pi}{\sqrt{n\pi(1 - \pi)}}\)</span></li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(n\)</span> and normality</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The binomial distribution converges to normality as <span class="math inline">\(n\)</span> increases</li>
<li>For fixed <span class="math inline">\(\pi\)</span>, the binomial distribution can be reasonably assumed to be normal when <span class="math inline">\(n[\min(\pi, 1–\pi)]\)</span> is as small as about 5 (Agresti, 2013, p.5)</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Statistical Inference with the Binomial distribution (Not developed)</strong>
<ul>
<li><strong>Wald test</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A test statistic in which the standard error nonnull estimated (not the standard error of population distribution under the null hypothesis)</li>
</ul></li>
<li><strong>The Wald statistic for probability</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li>$W = $</li>
</ul></li>
</ul></li>
<li><strong>The Wald z statistic</strong>
<ul>
<li><span class="math inline">\(\displaystyle z_W = \frac{p - \pi}{SE} = \frac{p - \pi}{\frac{\sqrt{\hat\pi(1 - \hat\pi)}}{n}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Multinomial distribution</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A discrete probability distribution for the discrete independent random variable (<span class="math inline">\(y\)</span>) of the combination of numbers with each number being the number of occurrence of each of the multiple possible outcomes in a sequence of a fixed/finite <span class="math inline">\(n\)</span> number of random independent and identical trial/experiment</li>
<li>The categorical distribution is a special case of the multinomial distribution where <span class="math inline">\(n = 1\)</span></li>
<li>The probability of obtaining a combination of <span class="math inline">\(n_1, n_2, \cdots, n_k\)</span> is denoted as <span class="math inline">\(\text{P}(n_1, n_2, \cdots, n_k)\)</span> where <span class="math inline">\(n_k\)</span> is the number of occurrence for outcome <span class="math inline">\(k\)</span> in a sequence of <span class="math inline">\(n\)</span> random, independent, and identical trials</li>
<li><details>
<summary>
Alternative text
</summary>
In 1 trial, there are multiple (but fixed) number of possible outcomes, the outcome of a trial is represented by a combination (e.g. if there are 4 possible outcomes, the combination could be 0, 1, 0, 0, meaning that the outcome for this trial is category 2). Now imagine we have <span class="math inline">\(16\)</span> of this trial, the combination could be something like 4, 4, 4, 4. The multinomial distribution models the probability of getting different combinations. In the case of 4, 4, 4, 4, this is a fair trial (the null hypothesis), where each of the categories have equal chance of occurrence, so this combination after <span class="math inline">\(16\)</span> trials would be the most probable (it has a probability of 0.50), whereas a combination of something like 6, 5, 3, 2 would be less probable in the null multinomial distribution
</details></li>
<li><strong>The outcome of a single multinomial trial (<span class="math inline">\(y_i\)</span>)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The outcome of a single random, independent and identical multinomial trial</li>
<li>The outcome can be one of multiple but fixed number of possible outcomes</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(y_i = (y_{i,1}, y_{i,2}, \cdots , y_{i,k})\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(k\)</span> - The number of possible outcomes of a single trial</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The outcome of a sequence of <span class="math inline">\(n\)</span> multinomial trials</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The number of occurrence of each of the <span class="math inline">\(k\)</span> outcomes after a sequence of <span class="math inline">\(n\)</span> random, independent, and identical trials</li>
<li>This is represented as a combination of <span class="math inline">\(k\)</span> numbers with each number representing the number of occurrence of each of the <span class="math inline">\(k\)</span> outcomes after a sequence of <span class="math inline">\(n\)</span> random, independent, and identical trials</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(y = (n_1, n_2, \cdots , n_k)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Multinomial probability mass function</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A function that models the probability of each of all possible outcome combinations</li>
<li>The multinomial distribution has <span class="math inline">\(K - 1\)</span> dimensions because <span class="math inline">\(y_{i,k}\)</span> is linearly dependent on the others and therefore is redundant</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{P}(n_1, n_2, \cdots , n_{k-1}) = \left( \frac{n!}{\Pi_{k = 1}^{K}{n_k!}} \right) \Pi_{k = 1}^{K}{\pi_{k}^{n_k}}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Parameters of a multinomial distribution</strong>
<ul>
<li><strong>Expectation</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(E(n_j) = n\pi_j\)</span></li>
</ul></li>
</ul></li>
<li><strong>Variance</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\sigma^2_{n_j} = n\pi_j(1-\pi_j)\)</span></li>
</ul></li>
</ul></li>
<li><strong>Covariance between any two outcomes</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\text{Cov}(n_j, n_k) = -n\pi_j\pi_k\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Poisson distribution</strong>
<ul>
<li><strong>History</strong>
<ul>
<li>Introduced by Poisson (1781 - 1840) and published with his probability theory in his work Recherches sur la probabilité des judgements en matié criminelle et en matiére civile (1837) where he theorised about the number of wrongful convictions in a given country by fousing on certain random variables N that count the number of discrete occurrenses that take place during a time-interval of given length</li>
<li>Newcomb (1860) applied the Poisson distribution to estimate the distribution of the number of stars found in a unit of space</li>
<li>Bortkiewicz (1898) applied the Poisson distribution to estimate the number of soldiers in the Prussian army killed accidentally by horse kicks (this experiment introduced the Poisson distribution to the field of reliability engineering)</li>
</ul></li>
<li><strong>Concept</strong>
<ul>
<li>A discrete probability distribution of the discrete independent random variable (<span class="math inline">\(y\)</span>) of the number of the “success” events in a sequence of an infinite number of Bernoulli trials/experiments (independent, identical) within a fixed time interval and space</li>
<li>The Poisson distribution is used for the number of events that occur randomly over a fixed window of time or space when outcomes in disjoint periods or regions are independent</li>
<li>The Poisson distribution can be used for the binomial case when <span class="math inline">\(n\)</span> is larger and <span class="math inline">\(\pi\)</span> is small (then <span class="math inline">\(\mu = n\pi\)</span>)</li>
<li>The Poisson distribution is conceptually similar to the binomial distribution, the difference is that the binomial distribution has a fixed number of trials (<span class="math inline">\(n\)</span>), meanwhile, the Poisson distribution has an infinite number of trials (an infinite population of trials)</li>
</ul></li>
<li><strong>Poisson probability mass function</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{P}(y) = \frac{e^{-\mu}\mu^{y}}{y!}~~~ y = 0:.\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(y\)</span> - The number of times an event occurred (sometimes it is denoted as <span class="math inline">\(k\)</span>)</li>
<li><span class="math inline">\(\mu\)</span> - The expected number of times an event occurred (sometimes it is denoted as <span class="math inline">\(\lambda\)</span>)</li>
</ul></li>
<li>*<strong>Notes</strong>
<ul>
<li>Sometimes it is expressed as such</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Mean of the Poisson PMF</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The number of occurrence of an event in the null Poisson distribution</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\mu = \text{E}(y_i) = \lambda\)</span></li>
</ul></li>
</ul></li>
<li><strong>Mode of the Poisson distribution</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The mode equals to the integer part of <span class="math inline">\(\mu\)</span></li>
</ul></li>
</ul></li>
<li><strong>Variance of the Poisson PMF</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The variance of the Poisson PMF is the same as its mean</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\text{Var}(y_i) = \text{E}(y_i)\)</span></li>
</ul></li>
</ul></li>
<li><strong>Skewness</strong>
<ul>
<li>The Poisson distribution approaches normal as <span class="math inline">\(\mu\)</span> increases (when <span class="math inline">\(\mu\)</span> is at least 10 it can be assumed to be normal)</li>
<li><strong>Mathematics</strong>
<ul>
<li>The skewness is described by the following equality</li>
<li><span class="math inline">\(\displaystyle \frac{\text{E}(y - \mu)^3}{\sigma^3} = \frac{1}{\sqrt{\mu}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Binomial and Poission distribution and the problem of Overdispersion</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Modelling count observations with binomial or Poission distributions often result in overdispersion.</li>
<li><span class="math inline">\(\mu\)</span> can vary because of unmeasured factor</li>
<li>Unconditionally,
<ul>
<li>The Expectation is
<ul>
<li><span class="math inline">\(E(y) = E[E(y | \mu)]\)</span></li>
</ul></li>
<li>The variance is
<ul>
<li><span class="math inline">\(\text{Var}(y) = E[\text{Var}(y|\mu)] + \text{Var}[E(y|\mu)]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Overdispersion</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The phenomenon in which the observed variability in the real world is larger than the variability predicted by the statistical model</li>
<li>This may cause inaccurate inferences</li>
<li>Overdispersion is a common feature because in practice populations are frequently heterogeneous</li>
<li>Count observations using the binomial or Poission distribution often encounter this problem</li>
</ul></li>
</ul></li>
</ul>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>Likelihood</strong>
</p>
<ul>
<li><strong>Likelihood</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The probability of the observed sample data/datum as a function of the parameters of the chosen statistical model/distribution</li>
<li>In the case of data (when there are multiple observations), it is the joint probability between the observations under the statistical model/distribution given the values of the parameters of the statistical model/distribution</li>
</ul></li>
<li><strong>Related terms</strong>
<ul>
<li><strong>Kernel</strong> - The part of a likelihood function that involves the model parameters (the relevant part of the likelihood function)</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta | X) = \text{PF}(x_i)\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(\theta\)</span> - The parameter of the chosen statistical model</li>
<li><span class="math inline">\(X\)</span> - The observed sample data</li>
</ul></li>
<li><strong><em>Notes</em></strong>
<ul>
<li>It can also be written as <span class="math inline">\(\text{P}(X | \theta)\)</span>, but this is less commonly used</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The likelihood function of a random sample</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A function that describes the likelihood of a random sample data/datum as a function of the values of the parameters of the chosen statistical model</li>
<li>In other words, it describes the probability of getting the sample data/datum under different values of the parameters of the statistical model</li>
<li>The graph of the likelihood function is the likelihood against the values of the parameter(s) of the chosen statistical model</li>
<li>It treats the sample data/datum is given and the parameter is a variable</li>
<li>It is the joint probability between the observations at different values of the parameter of the model</li>
<li>The graph is concave for most models</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li>$(; ) = _{i = 1}^{n}{f(x_i; )} $
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(f(x_i; \theta)\)</span> - The probability density function (PDF) for the variable of interest (in this example here the statistical model has only one parameter, <span class="math inline">\(\theta\)</span>, when it has two parameters, let’s say <span class="math inline">\(\sigma^2\)</span>, then it is expressed as <span class="math inline">\(f(x_i; \theta, \sigma^2)\)</span>)</li>
<li><span class="math inline">\(\mathbf{x} = (x_1, x_2, x_3, \cdots , x_n)&#39;\)</span> - The observed random variable/data</li>
</ul></li>
<li><strong><em>Notes</em></strong>
<ul>
<li><span class="math inline">\(\mathcal{L}(\theta; \mathbf{x})\)</span> can be denoted as <span class="math inline">\(\mathcal{L}(\theta)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Example</strong>
<ul>
<li>The beginning scenario
<ul>
<li>You have 5 observations in your data and you are hypothesising that they came from a common population with pdf <span class="math inline">\(f(x; \theta)\)</span></li>
</ul></li>
<li>The likelihood function is:
<ul>
<li>$(; ) = _{i = 1}^{n}{f(x_i; )} $</li>
</ul></li>
<li>Find the likelihood under all possible values of the parameter
<ul>
<li>Examples:
<ul>
<li>The likelihood of getting this sample data given that the true value of the parameter is 1
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 1; \mathbf{x}) = f(x_1; \theta= 1) \times f(x_2; \theta= 1) \times f(x_3; \theta= 1) \times f(x_2; \theta= 1) \times f(x_3; \theta= 1)\)</span></li>
</ul></li>
<li>The likelihood of getting this sample data given that the true value of the parameter is 2
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 2; \mathbf{x}) = f(x_1; \theta= 2) \times f(x_2; \theta= 2) \times f(x_3; \theta= 2) \times f(x_2; \theta= 2) \times f(x_3; \theta= 2)\)</span></li>
</ul></li>
<li>The likelihood of getting this sample data given that the true value of the parameter is 3</li>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 3; \mathbf{x}) = f(x_1; \theta= 3) \times f(x_2; \theta= 3) \times f(x_3; \theta= 3) \times f(x_2; \theta= 3) \times f(x_3; \theta= 3)\)</span></li>
</ul></li>
<li>The likelihood of getting this sample data given that the true value of the parameter is 4
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 4; \mathbf{x}) = f(x_1; \theta= 4) \times f(x_2; \theta= 4) \times f(x_3; \theta= 4) \times f(x_2; \theta= 4) \times f(x_3; \theta= 4)\)</span></li>
</ul></li>
<li>The likelihood of getting this sample data given that the true value of the parameter is 5
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 5; \mathbf{x}) = f(x_1; \theta= 5) \times f(x_2; \theta= 5) \times f(x_3; \theta= 5) \times f(x_2; \theta= 5) \times f(x_3; \theta= 5)\)</span></li>
</ul></li>
<li>The likelihood of getting this sample data given that the true value of the parameter is 6
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}(\theta = 6; \mathbf{x}) = f(x_1; \theta= 6) \times f(x_2; \theta= 6) \times f(x_3; \theta= 6) \times f(x_2; \theta= 6) \times f(x_3; \theta= 6)\)</span></li>
</ul></li>
</ul></li>
<li>Plot these likelihoods into a plot of likelihood against the value of the parameter
<ul>
<li>The likelihood graph will usually be concave</li>
<li>This is the likelihood graph for this sample</li>
</ul></li>
</ul></li>
<li><strong>Log likelihood function</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The log of the likelihood/likelihood function</li>
<li>The log likelihood function is often used instead of the likelihood function because it is more convenient to use and it simplifies many of the later calculations (e.g. it is a sum rather than product of terms)</li>
<li>No information is lost from logging the likelihood because the log is a one-to-one function</li>
<li>Since the log is a strictly increasing function, the values of the model parameters that maximise <span class="math inline">\(\mathcal{l}(\theta; \text{x})\)</span> are the same as the values that maximise <span class="math inline">\(\mathcal{L}(\theta; \mathbf{x})\)</span></li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{l}(\theta; \text{x})=\log{\mathcal{L}(\theta; \text{x})} = \sum_{i = 1}^{n}{\log f(x_i; \theta)}\)</span></li>
<li><strong><em>Notes</em></strong>
<ul>
<li><span class="math inline">\(\mathcal{l}(\theta; \text{x})\)</span> can be denoted as <span class="math inline">\(\mathcal{l}(\theta)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>Maximum Likelihood Estimation</strong>
</p>
<ul>
<li><strong>Maximum Likelihood Estimation</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>An estimation method in which the model parameters are estimated by finding the parameters of the statistical model that maximizes the likelihood of the data through setting the partial derivative of the likelihood function of the data to 0</li>
<li>Because the likelihood curve is concave, setting this to 0 will get the maxima of the curve; the point that represents the maximum likelihood of the data)</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li>The value of <span class="math inline">\(\theta\)</span> with the maximum likelihood of the data
<ul>
<li><span class="math inline">\(\hat\theta = Argmax\mathcal{L}(\theta; \mathbf{x})\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(Argmax\mathcal{L}(\theta; \mathbf{x})\)</span> - This notation means that <span class="math inline">\(\mathcal{L}(\theta; \mathbf{x})\)</span> achieves its maximum value at <span class="math inline">\(\hat\theta\)</span> - The value of <span class="math inline">\(\theta\)</span> with the maximum likelihood</li>
</ul></li>
</ul></li>
</ul></li>
<li>The value of <span class="math inline">\(\theta\)</span> with the maximum likelihood of the data is found through maximisation of the likelihood function by setting the partial derivative of the likelihood function to 0</li>
<li><span class="math inline">\(\displaystyle \frac{\partial\mathcal{L}(\theta)}{\partial \theta} = 0\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>The log likelihood function can be used but I just used the likelihood function here</li>
<li>This is an estimating equation (EE), an equation for estimating the population parameters</li>
<li>If there are multiple parameters (e.g. a normal distribution that has parameter <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>), the parameters are solved through setting each of the partial derivative for each of the parameters to 0</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Properties of the MLEs (THIS SECTION IS NOT DEVELOPED)</strong>
<ul>
<li><strong>Theorem 1</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>If the parameter of interest $$ is the parameter <span class="math inline">\(\theta\)</span> in some sort of function <span class="math inline">\(g(\theta)\)</span>, (<span class="math inline">\(\eta =g(\theta)\)</span>), then the mle of <span class="math inline">\(\theta\)</span> in the same function is the mle of <span class="math inline">\(eta\)</span> (<span class="math inline">\(\hat\eta\)</span>)</li>
<li><span class="math inline">\(g(\hat\theta)\)</span> is the MLE of <span class="math inline">\(\eta = g(\theta)\)</span></li>
<li><span class="math inline">\(\hat\eta = g(\hat\theta)\)</span></li>
<li>“In some situations, besides the parameter <span class="math inline">\(\theta\)</span>, we are also interested in the parameter <span class="math inline">\(\eta = g(\theta)\)</span>, it can be shown that the mle of <span class="math inline">\(\eta\)</span> is <span class="math inline">\(\hat\eta = g(\hat\theta)\)</span> where <span class="math inline">\(\hat\theta\)</span> is the mle of <span class="math inline">\(\theta\)</span>”</li>
</ul></li>
</ul></li>
<li><strong>Theorem 2</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The larger the sample size, the closer the mle is to the true parameter value ??? DON’T KNOW ABOUT THIS</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Hessian matrix</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A square matrix in which each of the elements of the matrix is a second-order partial derivative of the function of interest with respect to the square of each of the variables</li>
<li>A square matrix that describes the change in the rate of change at a particular point of a function (local curvature) of multiple variables<br />
</li>
<li>The Hessian matrix is a general mathematical concept and it is applied in statistics</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \mathbf{H}_f = \begin{bmatrix} \displaystyle \frac{\partial{}^2f}{\partial{x_{1}^{2}}} &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{1}} \partial{x_{2}}} &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{1}} \partial{x_{3}}} &amp; \displaystyle \cdots &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{1}} \partial{x_{n}}} \\ \displaystyle \frac{\partial{}^2f}{\partial{x_{2}} \partial{x_{1}}} &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{2}^2}} &amp;\displaystyle \frac{\partial{}^2f}{\partial{x_{2}} \partial{x_{3}}} &amp; \displaystyle \cdots &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{2}} \partial{x_{n}}} \\ \displaystyle \frac{\partial{}^2f}{\partial{x_{3}} \partial{x_{1}}} &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{3}}\partial{x_{2}} } &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{3}^2}} &amp; \displaystyle \cdots &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{3}} \partial{x_{n}}} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \displaystyle \frac{\partial{}^2f}{\partial{x_{n}} \partial{x_{1}}} &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{n}}\partial{x_{2}} } &amp; \displaystyle \frac{\partial{n}^f}{\partial{x_{n}} \partial{x_{3}}} &amp; \cdots &amp; \displaystyle \frac{\partial{}^2f}{\partial{x_{n}^2}} \end{bmatrix}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(\mathbf{H}_f\)</span> - The Hessian matrix of function <span class="math inline">\(\mathcal{f}\)</span></li>
<li><span class="math inline">\(\frac{\partial{}^2f}{\partial{x_{i}} \partial{x_{j}}}\)</span> - The second-order derivative of the function with respect to the cross-product of variable <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The Score</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The score is the slope of the log-likelihood function evaluated at a particular value of the parameter</li>
</ul></li>
</ul></li>
<li><strong>The Score at the true value of the parameter</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The slope of the (log) likelihood function evaluated at the true value of the parameter (<span class="math inline">\(\theta\)</span>)</li>
<li>The score is a variable because it is subject to sampling variation - That is, the score derived from a samples can be different from the scores derived from other samples</li>
<li>In reality, we will never know this because the true value of the population parameter is unknown</li>
</ul></li>
<li><strong>A single observation case</strong>
<ul>
<li><strong>The score</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><strong>The likelihood function</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle \mathcal{L}\left( \theta; x \right) &amp;= \prod_{i = 1}^{n = 1}{f(x_i; \theta)} \\ &amp;= f(x; \theta) \end{aligned}\)</span></li>
</ul></li>
<li><strong>The log likelihood</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \mathcal{l}(\theta; x) &amp;= \log\mathcal{L}\left( \theta; x \right) \\ &amp;= \log f(x; \theta) \end{aligned}\)</span></li>
</ul></li>
<li><strong>The score (first derivative of the log likelihood evaluated at the true value of the parameter)</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}S_\theta &amp;= \displaystyle \frac{\partial \mathcal{l}(\theta; x)}{\partial \theta} \\ &amp;= \frac{\partial \log f(x_i; \theta)}{\partial \theta} \end{aligned}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The expectation of the Score</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle E(S_\theta) = E\left( \frac{\partial \log f(x_i; \theta)}{\partial \theta}\right)\)</span></li>
</ul></li>
<li><strong>The expectation of the score is 0</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The mean of the scores all with a single observation and evaluated at the true value of the parameter is 0</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle E(S_\theta) = E\left( \frac{\partial \log f(x_i; \theta)}{\partial \theta}\right) = 0\)</span></li>
</ul></li>
<li><strong>Proof</strong>
<ul>
<li><strong>Begin with the identity</strong>
<ul>
<li><span class="math inline">\(\displaystyle 1 = \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~ ~ dx = \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)} ~ dx\)</span></li>
</ul></li>
<li><strong>The first derivative under the integral sign</strong>
<ul>
<li><span class="math inline">\(\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}} ~ dx\)</span></li>
</ul></li>
<li><strong>Reversing the chain rule for log</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle 0 &amp;= \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx \\ &amp;= \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx \end{aligned}\)</span>
<ul>
<li><strong><em>Reminder</em></strong>
<ul>
<li><strong>The chain rule for log</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}y &amp;= \log{(g(x))} \\ \displaystyle \frac{dy}{dx} &amp;= \frac{1}{g(x)} \times g&#39;(x) \end{aligned}\)</span></li>
</ul></li>
<li><strong>Hence</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \int_{-\infty}^{\infty}{\frac{\partial \log{f(x ;\theta)}}{\partial \theta} \times f(x; \theta) ~ dx} &amp;= \displaystyle \int_{-\infty}^{\infty}{\frac{1}{f(x; \theta)} \times f&#39;(x; \theta) \times f(x; \theta) ~ dx} \\ &amp;= \displaystyle \int_{-\infty}^{\infty}{\frac{1}{f(x; \theta)} \times \frac{\partial f(x; \theta)}{\partial \theta} \times f(x; \theta) ~ dx} \\ &amp;= \displaystyle \int_{-\infty}^{\infty}{\frac{\partial f(x; \theta)}{\partial \theta f(x; \theta)} \times f(x; \theta) ~ dx} \end{aligned}\)</span></li>
<li>In the derivation above, it utilises this rule but in the reversed order</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Expressed as expectation</strong>
<ul>
<li><span class="math inline">\(\displaystyle 0 = E\left[ \frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The variance of the score</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The sampling variation of the scores given the true value of <span class="math inline">\(\theta\)</span> (alternatively speaking, it is the variation of the scores evaluated at the true value of <span class="math inline">\(\theta\)</span> due to sampling error)</li>
<li>The imagination comes back again, similar as before, imagine you know the true value of the parameter, you then take many samples, each time you take a sample, you calculate the score with respect to the true value of the parameter, after doing this for each of the samples, you will have many scores, each coming from each sample, you then calculate the variance of the scores</li>
</ul></li>
<li><strong>Variance defined as the second moment about the mean</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The variance can be defined as the second moment about the mean</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Var}(S) = \text{E}\left[ \left(\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right)^2\right]\)</span></li>
</ul></li>
</ul></li>
<li><strong>Variance defined as the negative of the expectation of the second derivative of the likelihood function</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Through derivations, it can be shown that the variance equals to the negative of the expectation of the second derivative of the likelihood function evaluated at the true value of the parameter. In other words, it is the average curvature of the likelihood functions at the true value of the parameter in the parameter space.</li>
<li><strong>Mathematics</strong>
<ul>
<li><strong>Begin with the identity (this is seen before in the expectation section)</strong></li>
<li><span class="math inline">\(\begin{aligned}\displaystyle 1 &amp;= \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~ ~ dx \\ &amp;= \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)} ~ dx \end{aligned}\)</span></li>
<li><strong>The first derivative under the integral sign (this is seen before in the expectation section)</strong>
<ul>
<li><span class="math inline">\(\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}} ~ dx\)</span></li>
</ul></li>
<li><strong>Which can be reexpressed as (this is seen before in the expectation section)</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle 0 &amp;= \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx \\ &amp;= \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx \end{aligned}\)</span></li>
</ul></li>
<li><strong>Differentiate again (the second derivative)</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle 0 &amp;= \int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx + \int_{-\infty}^{\infty}{\frac{\partial \log f(x; \theta)}{\partial \theta} \frac{\partial \log f(x; \theta)}{\partial \theta} ~ f(x; \theta) ~ dx} \\ \displaystyle 0 &amp;= \int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx + \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2} ~ f(x; \theta)~dx\\ \displaystyle -\int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx &amp;= \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2}~ f(x; \theta)~dx \end{aligned}\)</span></li>
</ul></li>
<li><strong>Expressed as expectations</strong>
<ul>
<li><span class="math inline">\(\displaystyle -\int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx = \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2}~ f(x; \theta)~dx \\ \displaystyle -E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right) = E\left[\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2\right]\)</span></li>
</ul></li>
<li>Hence, you can see that the second moment about the mean (<span class="math inline">\(E\left[\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2\right]\)</span>) equals to the negative of the expectation of the curvature of the likelihood function evaluated at the true value of the parameter (<span class="math inline">\(-E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right)\)</span>)</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Which expression is preferred?</strong>
<ul>
<li>Usually the second definition of the variance is preferred as it is usually easier to compute than the first definition</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>&amp;nbsp
- <strong>Fisher Information</strong>
- <strong>Concept (general)</strong>
- A quantity that quantifies the amount of information that any datum/observation in a data/datum/sample carries about an unknown parameter of a statistical model of that random variable
- The Fisher information is the variance of the score evaluated at 1 observation
- <strong>Mathematics</strong>
- <span class="math inline">\(\begin{aligned}\displaystyle I_1(\theta) &amp;= \text{Var}(S) \\ \displaystyle &amp;= \text{Var}\left[\frac{\partial \mathcal{l}(\theta; x)}{\partial \theta} \right] \\ \displaystyle &amp;= \text{Var}\left[\frac{\partial \log f(x_i; \theta)}{\partial \theta}\right] \end{aligned}\)</span>
- <strong><em>Notes</em></strong><br />
- <span class="math inline">\(I_1(\theta)\)</span> - Usually it is expressed as <span class="math inline">\(I(\theta)\)</span> but I expressed it as such to indicate that this is the Information from one observation
- <strong>Information defined as the second moment of about the mean</strong>
- <strong>Concept</strong>
- As seen, the variance of the score can be defined in terms of the second moment of about the mean, since the Fisher Information is the variance of the score at the true value of the parameter, the Fisher Information can be interpreted the same way
- <strong>Information defined as the curvature</strong>
- <strong>Concept</strong>
- As seen, the variance of the score can be defined in terms of the curvature of the likelihood function at the true value of the parameter, which means that Fisher information can be interpreted as the same way, which is pretty intuitive
- Information can be expressed in terms of the negative of the expectation of the curvature of the likelihood function evaluated at the true value of the parameter
- Hence, the greater the curvature of the likelihood function at the true value of the parameter, the more information the data/datum has about the unknown parameters of the model (in the extreme case when the likelihood function is at the highest at a single value of the parameter and 0 at all other values of the parameter, in other words, the likelihood is non-zero at a single point in the parameter space, the data/datum contains complete information about the parameter)
- The smaller the curvature of the likelihood function at the true value of the parameter, the less information the data has about the unknown parameters of the model (in the extreme case when the likelihood function is flat, that is, when the likelihood is the same across values of the parameter, then the data/datum contains no information at all about the value of the parameter)
- <strong>Mathematics</strong>
- <span class="math inline">\(\begin{aligned}\displaystyle I(\theta) &amp;= \text{Var}(S) \\ &amp;= -E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right)\end{aligned}\)</span>
- <strong>A multiple-observation case</strong>
- <strong>Score</strong>
- <strong>Mathematics</strong>
- <strong>The likelihood function</strong>
- <span class="math inline">\(\displaystyle \mathcal{L}(\theta; X) = \prod_{i = 1}^{n}{f(x; \theta)}\)</span>
- <strong>The log likelihood function</strong>
- <span class="math inline">\(\displaystyle \mathcal{l}(\theta; X) = \log{\mathcal{L}(\theta; X)} = \sum_{i = 1}^{n}{\log{f(x; \theta)}}\)</span>
- <strong><em>Notes</em></strong>
- The log of a product is the sum of the log of each factor in the product
- <strong>The Score (the first derivative of the log likelihood function) (NOT SURE ABOUT THIS)</strong>
- <span class="math inline">\(\begin{aligned} \displaystyle S_n &amp;= \frac{\partial \mathcal{l}(\theta; X) }{\partial \theta} \\ \displaystyle &amp;= \frac{\partial }{\partial \theta} \mathcal{l}(\theta; X) \\ \displaystyle &amp;= \frac{\partial}{\partial \theta} \sum_{i = 1}^{n}{\log{f(x; \theta)}} \\ \displaystyle &amp;= \sum_{i = 1}^{n}{\frac{\partial}{\partial \theta}\log{f(x; \theta)}} \\ \displaystyle &amp;= \sum_{i = 1}^{n}{\frac{\partial \log{f(x; \theta)}}{\partial \theta}} \\ \displaystyle &amp;= \sum_{i = 1}^{n}{S_1} \\ &amp;= nS_1 \end{aligned}\)</span>
- <strong><em>Note</em></strong>
- <strong>The sum rule of differentiation</strong> - The derivative of a sum is the sum of the derivative of each term in the sum<br />
- <strong>Expectation of the Score</strong>
- <strong>Mathematics</strong>
- <span class="math inline">\(\begin{aligned}\displaystyle \text{E}(S_n) &amp;= \text{E}\left[\frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &amp;= \text{E}\left[ \sum_{i = 1}^{n}{\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}}\right]\\ &amp;= \sum_{i = 1}^{n}{\text{E}\left[ \frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right]} \end{aligned}\)</span>
- The expectation of each score is 0, hence:
- <span class="math inline">\(\begin{aligned} \text{E}(S_n) &amp;= \sum_{i = 1}^{n}{0} \\ &amp;= 0\end{aligned}\)</span>
- <strong>Variance of the score</strong>
- <strong>Variance defined as the second moment about the mean</strong>
- <strong>Concept</strong>
- The variance of the score in a sample with n observations is n times the information of any one observation in the sample
- <strong>Mathematics</strong>
- <span class="math inline">\(\begin{aligned} \displaystyle \text{Var}(S) &amp;= \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &amp;= \text{Var}\left[\sum_{i = 1}^{n}{\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}}\right] \\ &amp;= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta}\right]} + \sum_{j = 1}^{J}{\sum_{i = 1}^{I}{\text{Cov}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta} \frac{\partial \log{f(x_j; \theta)}}{\partial \theta}\right]}} \end{aligned}\)</span>
- <strong><em>Notes</em></strong>
- <strong>Bienaymé’s identity</strong>
- <strong>Concept</strong>
- The variance of the sum is the sum of the variance of each of the elements plus the sum of the covariance of each pair of the elements
- If the random variables are uncorrelated, that is, they have a covariance of 0, then it simplies that the variance of the sum is the sum of the variance of the elements
- <strong>Mathematics</strong>
- $ (<em>{i = 1}^{n}{x_i}) = </em>{i = 1}^{n}{(x_i)} + <em>{j = 1}^{J}{</em>{i = 1}^{I}{( x_i, x_j)}} $
- <strong>Assuming that the scores are uncorrelated (having a correlation of 0)</strong>
- <span class="math inline">\(\begin{aligned}\displaystyle \text{Var}\left(S_n\right) &amp;= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta}\right]} \\ &amp;= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x; \theta)}}{\partial \theta}\right]} \\ &amp;= n\times\text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ &amp;= n\text{Var}(S_1)\end{aligned}\)</span>
- <strong>Fisher Information</strong>
- <strong>Concept</strong>
- The Information in a sample with n observations is n times the Information from any one observation in the sample
- <strong>Mathematics</strong>
- <span class="math inline">\(\begin{aligned}\displaystyle \text{Var}\left(S_n\right) &amp;= n\text{Var}(S_1) \\ I_n(\theta) &amp;= nI_1(\theta)\end{aligned}\)</span></p>
<ul>
<li><strong>Variance of model parameters</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The variance of a model parameter or the variance-covariance matrix of a vector of model parameters</li>
<li>Under regularity conditions, the variance-covariance of model parameters is the inverse of the information weighted by n (sample size) (Rao, 1973, p.364; Rao Cramer lower bound)</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><strong>For one parameter</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \text{Var}(\hat\theta) &amp;= \sigma_{\hat\theta}^{2}= \frac{1}{n}I^{-1}(\hat\theta) = \frac{1}{nI(\hat\theta)} \\ \displaystyle \text{SE}(\hat\theta) &amp;= \sqrt{\sigma_{\hat\theta}^{2}} = \sqrt{\frac{1}{n}I^{-1}(\hat\theta)} = \sqrt{\frac{1}{nI(\hat\theta)}} \end{aligned}\)</span></li>
</ul></li>
<li><strong>For multiple parameters</strong>
<ul>
<li><span class="math inline">\(\displaystyle \textbf{Cov}(\hat\theta) = \frac{1}{n}\textbf{I}^{-1}(\theta)\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>This is a variance-covariance matrix, the variance for each of the model parameters are in the diagonal. To get the Standard Error of each of the model parameters, square the variance of the model parameters.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>NHST for MLE</strong>
<ul>
<li>Wald test</li>
<li>Likelihood ratio</li>
<li>Score statistic</li>
</ul></li>
<li><strong>Wald test (Wald, 1943)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Inferential Test statistic based on the (log) likelihood function</li>
</ul></li>
<li><strong>The Wald statistic</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle W = \frac{(\hat\theta - \theta_0)^2}{\sigma^2_{\theta}}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li>$$ - The MLE</li>
<li><span class="math inline">\(\theta_0\)</span> - The value of the parameter under the null hypothesis</li>
<li><span class="math inline">\(\sigma^2_{\theta}\)</span>
<ul>
<li>The sampling variance of the population parameter under the alternative hypothesis</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Distribution of the Wald statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The Wald statistic has an approximate central Chi-squared distribution with df of 1</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(W \sim \chi^2(1)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>z-transformed Wald statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The Wald statistic transformed into a z normal statistic</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(z_W = \sqrt{W}\)</span></li>
</ul></li>
<li><strong>Distribution of the z Wald statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The z Wald statistic has an approximate z normal distribution</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(z_W \sim \mathcal{N}(df)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Likelihood ratio test (Wilks test)</strong>
<ul>
<li><strong>The likelihood ratio test statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The ratio of the likelihood under the alternative hypothesis and the likelihood under the null hypothesis</li>
<li>The squared vertical deviation between the maximised likelihood under the alternative hypothesis and the likelihood of the null hypothesized value of the parameter under the alternative hypothesis</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle -2\log \Lambda = -2 \log\left[ \frac{\mathcal{L}{(\theta_0)}}{\mathcal{L}({\theta_1})}\right] = -2\left[\mathcal{L}{(\theta_0)} - \mathcal{L}{(\theta_1)}\right]\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(L\)</span> - Maximised log-likelihood function</li>
<li><span class="math inline">\(\mathcal{L}{(\theta_1)}\)</span> - The maximised likelihood of the value of the parameter given the data (under the alternative hypothesis)</li>
<li><span class="math inline">\(\mathcal{L}{(\theta_0)}\)</span> - The likelihood of the null hypothesised value of the parameter in the likelihood function given the data (under the alternative hypothesis)</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Degrees of freedom of the likelihood ratio test statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The df is the difference in the dimensions of the parameter spaces under <span class="math inline">\(H_0 \cup H_1\)</span> and <span class="math inline">\(h_0\)</span></li>
</ul></li>
</ul></li>
<li><strong>The distribution of the likelihood ratio test statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Under certain regularity conditions, the null distribution of the likelihood ratio statistic tends towards a chi-squared distribution with 1 degrees of freedom as sample size increases</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li>$^2(1) \ or \ -2 ^2(1) $</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Score statistic (Lagrange multiplier test)</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Based on the slope and expected curvature at the null hypothesised value of the parameter in the log-likelihood function</li>
</ul></li>
<li><strong>The score statistic</strong>
<ul>
<li><strong>The z score statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The normal z version of the score statistic</li>
<li>It is the ratio of the slope of the likelihood function of the parameter at the null hypothesised value of the parameter to the standard error of the slope at the null hypothesised value of the parameter</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \frac{\mathcal{l&#39;}(\theta_0)}{\sqrt{I(\theta_0)}}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(\mathcal{l&#39;}(\theta_0)\)</span> - The slope of the likelihood function of the parameter at the null hypothesised value of the parameter</li>
<li><span class="math inline">\(\sqrt{I(\theta_0)}\)</span> - The standard error of the slope of the likelihood function of the parameter at the null hypothesised value of the parameter - The standard error depends on the curvature of the likelihood function of the parameter at the null hypothesised value of the parameter - The information evaluated at the null hypothesised value of the parameter</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \frac{\mathcal{l&#39;}(\theta_0)^2}{I(\theta_0)}\)</span>
<ul>
<li><strong><em>Where</em></strong>
<ul>
<li><span class="math inline">\(\mathcal{l&#39;}\)</span> - The first derivative of the log likelihood function</li>
<li><span class="math inline">\(\mathcal{l&#39;}(\theta_0)^2\)</span> - The slope at the null hypothesised value of the parameter in the log likelihood function (sub in the null hypothesised value of the parameter into the first derivative of the log likelihood function and you will get this)</li>
<li><span class="math inline">\(I\)</span> - Information</li>
<li><span class="math inline">\(I(\theta_0)\)</span> - - The information at the null hypothesised value in the likelihood function - The variance of the slope of the likelihood function under the null hypothesis (those that are close to and around the maximum (slope of 0))</li>
</ul></li>
<li><strong><em>Notes</em></strong>
<ul>
<li>Some textbooks (e.g. Hogg and McKean) say it’s like this <span class="math inline">\(\displaystyle \frac{\mathcal{L&#39;}(\theta_0)^2}{nI(\theta_0)}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Central Distribution of the score statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The score statistic under the null hypothesis has a central Chi-square distribution</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>z transformed score statistic</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The score statistic can be transformed into a z normal statistic under the null hypothesis that has an approximate central normal distribution</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \sqrt{\frac{S(\theta_0)^2}{I(\theta_0)}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Evaluating the three tests</strong>
<ul>
<li>As <span class="math inline">\(n\)</span> increases towards infinity, the three tests have asymptotic equivalences (Cox and Hinkley, 1974, Sec. 9.3). For small to moderate sample sizes, the likelihood-ratio and score tests tend to be more reliable than the Wald test, that is that they vaeh an actual error rate closer to the nominal level</li>
</ul></li>
<li><strong>Maximum Likelihood Estimation for binomial Parameter</strong>
<ul>
<li><strong>MLE for the population parameter</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The log likelihood of the kernal</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><strong>The PMF of the binomial distribution</strong>
<ul>
<li><span class="math inline">\(\displaystyle P(y) = {n\choose y} \pi^y (1 - \pi)^{n - y} ~~~, y = 0:n\)</span></li>
</ul></li>
<li><strong>The log likelihood function:</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \mathcal{l}(\pi)&amp;=\log{\left[\pi^{y}(1-\pi)^{n-y}\right]} \\ \displaystyle &amp;= y\log(\pi)+(n-y)\log(1-\pi) \end{aligned}\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>Only the kernal of the PMF of the binomial distribution contains the parameters and relevant, therefore, only the kernal is used</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The first derivative of the likelihood function:</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \frac{\partial{\mathcal{l}(\pi)}}{\partial{\pi}} \displaystyle &amp;= \frac{y}{\pi} - \frac{n - y}{1- \pi} \\ \displaystyle &amp;= \frac{y - n\pi}{\pi(1-\pi)} \end{aligned}\)</span></li>
</ul></li>
<li><strong>Maximisation problem: set the derivative of the log likelihood function to 0 and find <span class="math inline">\(\pi\)</span> (the estimating equation)</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \frac{y - n\pi}{\pi(1-\pi)} &amp;= 0 \\ \displaystyle y - n\pi &amp;= 0 \\ \displaystyle \hat\pi &amp;= \frac{y}{n}\end{aligned}\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>As you can see, this is the sample proportion of success for the <span class="math inline">\(n\)</span> trials - This is the MLE of the population probability</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Information</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle I_{\pi} =-E\left(\frac{\partial^2 f}{\partial \pi^2}\right) = E\left[ \frac{y}{\pi^2} - \frac{n-y}{(1-\pi)^2}\right] = \frac{n}{\pi(1-\pi)}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Variance of <span class="math inline">\(\hat\pi\)</span></strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The variance of the parameter estimate in the distribution under the null hypothesis based on the ML method</li>
<li>It is estimated from the variance of the sample</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \sigma_{\hat\pi}^{2} &amp;= I^{-1} \\ \displaystyle \sigma_{\hat\pi}^{2} &amp;= -E\left(\frac{\partial^2 f}{\partial \pi^2}\right)^{-1} \\ \displaystyle &amp;= E \left[ \frac{y}{\pi^2} + \frac{n-y}{(1-\pi)^2} \right]^{-1} \\ \displaystyle &amp;= \left[\frac{n}{\pi(1 - \pi)}\right]^{-1} \\ \displaystyle &amp;= \frac{\pi(1-\pi)}{n} \end{aligned}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Standard error</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \sigma_{\hat\pi} &amp;= \sqrt{\sigma_{\hat\pi}^{2}} \\ &amp;= \sqrt{\frac{\pi(1-\pi)}{n}} \end{aligned}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Confidence Interval (Not yet developed)</strong>
<ul>
<li><strong>Wald confidence interval</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The Wald confidence interval uses the normal approximation</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(CI = \hat\pi ± z_{1-\frac{\alpha}{2}} \times \sigma_{\hat\pi}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Others</strong>
<ul>
<li>A marked divergence in results of Wald and Likelihood ratio inference indicates that the distribution of the parameter may not be close to normality</li>
</ul></li>
</ul></li>
<li><strong>NHST of the binomial parameter <span class="math inline">\(\hat\pi\)</span></strong>
<ul>
<li><strong>Wald test</strong>
<ul>
<li><strong>The z Wald statistic</strong></li>
<li><strong>Mathematics</strong><br />
</li>
<li><span class="math inline">\(\displaystyle z_W = \frac{\hat\pi - \pi_0}{\sigma_{\hat\pi}} = \frac{\hat\pi - \pi_0}{\sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}}\)</span></li>
</ul></li>
<li><strong>Score statistic test</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Since the Wald statistic uses the standard error evaluated at <span class="math inline">\(\hat\pi\)</span> and the score statistic uses the standard error evaluated at <span class="math inline">\(\pi_0\)</span>, the score statistic is preferred because it uses the actual null SE rather than an estimate of the null SE</li>
</ul></li>
<li><strong>The score statistic</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li>$ = $</li>
<li>Finding the slope of the likelihood function at the null hypothesised value of the parameter (<span class="math inline">\(S(\pi_0)^2\)</span>)
<ul>
<li>The first derivative of the likelihood function for <span class="math inline">\(\pi\)</span>
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{l}(\pi) = \frac{y - n\pi}{\pi(1-\pi)}\)</span></li>
</ul></li>
<li>Sub in <span class="math inline">\(\pi_0\)</span>
<ul>
<li><span class="math inline">\(\displaystyle S(\pi_0) = \frac{y - n\pi_0}{\pi_0(1-\pi_0)}\)</span></li>
</ul></li>
<li>Square it
<ul>
<li>$^2 $</li>
</ul></li>
</ul></li>
<li>Finding the SE of the slope under the null hypothesis (<span class="math inline">\(I(\pi_0)\)</span>)
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle I(\pi_0) &amp;= -E\left(\frac{\partial{}^2f}{\partial{x_{1}^{2}}}\right) \\ \displaystyle &amp;= -E\left(\frac{\partial{}^2 \mathcal{L}(\pi)}{\partial{\pi_0^{2}}}\right) \\ \displaystyle &amp;= \frac{n}{\pi_0 (1 - \pi_0)} \end{aligned}\)</span></li>
</ul></li>
<li>Hence
<ul>
<li><span class="math inline">\(\displaystyle \frac{S(\pi_0)^2}{I(\pi_0)} = \frac{\left[\frac{y - n\pi_0}{\pi_0(1-\pi_0)}\right]^2}{\frac{n}{\pi_0 (1 - \pi_0)}} = \frac{(y - n\pi_0)^2}{\frac{\pi_0(1-\pi_0)}{n}} = \frac{(\hat\pi - \pi_0)^2}{\frac{\pi_0(1-\pi_0)}{n}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Continuity correction</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A correction made when a discrete distribution is approximated by a continuous distribution</li>
</ul></li>
</ul></li>
</ul>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>The Generalised Linear Model</strong>
</p>
<ul>
<li><strong>Concept</strong>
<ul>
<li>An extension of ordinary regression models to encompass non-normal distributions of the outcome variable/residuals</li>
<li>There three components of GLM
<ul>
<li>Random component</li>
<li>Systematic component</li>
<li>Link function</li>
</ul></li>
<li>Random component
<ul>
<li>Identifies the outcome variable and its probability distribution</li>
</ul></li>
<li>Systematic component
<ul>
<li>Specifies explanatory variables used in a linear combination</li>
</ul></li>
</ul></li>
<li><strong>Link function</strong>
<ul>
<li>A function in Generalised Linear Models that maps the random with the systematic components</li>
<li><strong>Types of link function</strong>
<ul>
<li>Identity link function</li>
<li>Logit link function</li>
<li></li>
<li></li>
</ul></li>
</ul></li>
</ul>
<p style="margin-bottom: 0px; font-size: 20px; ">
<strong>Other stuff</strong>
</p>
<ul>
<li><strong>Unbiasedness of an estimator</strong>
<ul>
<li><strong>Definition</strong>
<ul>
<li>Let <span class="math inline">\(x_1, x_2, x_3, \cdots , x_n\)</span> be a sample on a random variable <span class="math inline">\(X\)</span> with pdf <span class="math inline">\(f(x; \theta)\)</span>. Let <span class="math inline">\(S = S(x_1, x_2, x_3, \cdots , x_n)\)</span> be a statistic. <span class="math inline">\(S\)</span> is an unbiased estimator of the population parameter <span class="math inline">\(\theta\)</span> if <span class="math inline">\(E(S) = \theta\)</span></li>
</ul></li>
</ul></li>
<li><strong>Cramér-Rao Lower Bound</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The CRLB states that the variance of an estimator cannot be lower than the CRLB</li>
<li>That is, the CRLB is the smallest possible variance of an estimator</li>
</ul></li>
<li><strong>For unbiased or biased estimators</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li>This is for the case when <span class="math inline">\(\hat\theta\)</span> can be an unbiased or biased estimator of <span class="math inline">\(\theta\)</span>, that is when the expectation of <span class="math inline">\(\hat\theta\)</span> is not <span class="math inline">\(\theta\)</span> but some kind of function of this (e.g. <span class="math inline">\(k(\theta)\)</span>)</li>
<li>Let <span class="math inline">\(x_1, x_2, x_3, \cdots, x_n\)</span> be idd with a pdf <span class="math inline">\(f(x; \theta)\)</span>. Let <span class="math inline">\(S = u(x_1, x_2, x_3, \cdots, x_n)\)</span> be a sample statistic with a mean <span class="math inline">\(E(S) = E[u(x_1, x_2, x_3, \cdots, x_n)] = k(\theta)\)</span>. Under the first 4 regularity conditions:
<ul>
<li><span class="math inline">\(\displaystyle \text{Var}(\theta) ≥ \frac{\left[k&#39;(\theta)\right]^2}{n I(\theta)}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>For unbiased estimators</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li>If <span class="math inline">\(S = u(x_1, x_2, x_3, \cdots, x_n)\)</span> is an unbiased estimator of <span class="math inline">\(\theta\)</span>, so that <span class="math inline">\(k(\theta) = \theta\)</span>, then the Cramér-Rao inequality becomes:</li>
<li><span class="math inline">\(\displaystyle \text{Var}(\hat\theta) ≥ \frac{1}{I(\theta)}\)</span></li>
</ul></li>
<li><strong>Proof</strong>
<ul>
<li><strong>Scenario</strong>
<ul>
<li>Let <span class="math inline">\(T = t(X)\)</span> be a sample statistic that is an estimator of the true value of the parameter <span class="math inline">\(\theta\)</span>.</li>
<li>To generalise the proof to accommodate both unbiased and biased estimator, let’s assume that <span class="math inline">\(T\)</span> can be a biased or unbiased estimator, hence, let’s express the expectation of <span class="math inline">\(T\)</span> as <span class="math inline">\(\text{E}(T) = g(\theta)\)</span> (So that if <span class="math inline">\(T\)</span> is an unbiased estimator, then <span class="math inline">\(g()\)</span> would be an identity function).</li>
<li>Let <span class="math inline">\(f(x; \theta)\)</span> be the pdf of the random variable <span class="math inline">\(X\)</span></li>
<li><strong>The log-likelihood function</strong>
<ul>
<li><span class="math inline">\(\mathcal{l}(\theta; X)\)</span></li>
</ul></li>
<li><strong>The score</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle S &amp;= \frac{\partial \log \mathcal{f}(x; \theta) }{\partial \theta} \\ &amp;= \frac{1}{f(x; \theta)} \times \frac{\partial f(x; \theta)}{\partial \theta} \\ &amp;= \frac{\partial f(x; \theta)}{\partial \theta f(x; \theta)}\end{aligned}\)</span></li>
</ul></li>
</ul></li>
<li><strong>Covariance of <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span></strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Cov}(S, T) = \text{E}\left[ (S - \text{E}(S)) (T - \text{E}(T))\right]=\text{E}(ST) - \text{E}(S)\text{E}(T)\)</span></li>
<li>Since <span class="math inline">\(\text{E}(S)\)</span> is 0 (proof is in the Score section), the covariance simplifies to:</li>
<li><span class="math inline">\(\displaystyle \text{Cov}(S, T) =\text{E}(ST)\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>The definition of the covariance of 2 random variables is:
<ul>
<li><span class="math inline">\(\displaystyle \text{Cov}(X, Y) = \text{E}\left[ (X - \text{E}(X)) (Y - \text{E}(Y))\right]=\text{E}(XY) - \text{E}(S)\text{E}(T)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Expanding the expression</strong>
<ul>
<li><span class="math inline">\(\begin{aligned}\displaystyle \text{Cov}(S, T) &amp;= \text{E}(ST) \\ &amp;= \text{E}\left[ \left( \frac{\partial f(x; \theta)}{\partial \theta f(x; \theta)}\right) \times T\right]\end{aligned}\)</span></li>
</ul></li>
<li><strong>Expressing it as an integral</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \text{Cov}\left( S, T\right) &amp;= \text{E}\left[ \left( \frac{\partial f(x; \theta)}{\partial \theta f(X; \theta)}\right) \times T\right] \\ &amp;= \int_{-\infty}^{\infty}{\frac{\partial f(x; \theta)}{\partial \theta f(X; \theta)} \times t(x) f(x; \theta) ~ dx} \\ &amp;= \frac{\partial}{\partial \theta}\int_{}^{}{t(x) f(x; \theta) ~ dx} \\ &amp;= \frac{\partial}{\partial \theta}\text{E}(T) \\ &amp;= g&#39;(\theta) \end{aligned}\)</span> |||||||||||||||||||STOPPED HERE|||||||||||||||</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Efficient Estimator</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>A sample statistic is an efficient estimator of the population parameter <span class="math inline">\(\theta\)</span> only if the variance of the sample statistic is equal to the Cramér-Rao lower bound</li>
</ul></li>
<li><strong>Efficiency</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The efficiency of an estimator is quantified as the ratio of the Cramér-Rao lower bound to the actual variance of an unbiased estimator</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Efficiency} = \frac{\textit{CRLB}}{\text{Var}(\theta)} \\ \displaystyle e(\hat\theta_{1n}) = \frac{\frac{1}{I(\theta_0)}}{\sigma^2_{\hat\theta_{1n}}}\)</span></li>
</ul></li>
<li><strong>Interpretation</strong>
<ul>
<li>According to the CRLB, the variance cannot be lower than the CRLB</li>
<li>Hence, efficiency ranges from asymptotic 0 to 1</li>
<li>An efficiency of 1 means that the estimator is asymptotically efficient</li>
<li>An efficiency smaller than 1 means that the estimator is inefficient</li>
<li>The smaller the efficiency below 1 and towards 0, the less efficient is the estimator</li>
</ul></li>
</ul></li>
<li><strong>MLE and efficiency</strong>
<ul>
<li>It can be shown that under regularity conditions, mles achieve an efficiency of 1 asymptotically. In other words, the variances of mles achieve their Cramér-Rao lower bounds asymptotically</li>
</ul></li>
</ul></li>
<li><strong>Regularity conditions of MLEs (DON’T FUCKING KNOW! Not developed)</strong>
<ol style="list-style-type: decimal">
<li>The variables are independent and identically distributed with density <span class="math inline">\(f(y; \theta)\)</span></li>
<li>The parameter space <span class="math inline">\(\Theta\)</span> is compact</li>
<li>The value of the parameter is identified</li>
<li>The likelihood function is continuous in <span class="math inline">\(\theta\)</span></li>
<li><span class="math inline">\(E_{\theta_0} \log f(Y; \theta)\)</span> exists</li>
<li>The log-likelihood function is such that <span class="math inline">\(\frac{1}{n}\mathcal{L}(y; \theta)\)</span> converges in probability to <span class="math inline">\(E_{\theta_0} \log f(Y; \theta)\)</span> uniformly in <span class="math inline">\(\theta \in \Theta\)</span></li>
<li>The pdf is at least twice differentiable as a function of <span class="math inline">\(\theta\)</span></li>
<li>Integration and differential operators are interchangeable - The order of integration and differentiation can be interchanged</li>
<li>The information matrix exists and is non-singular</li>
<li>The integral <span class="math inline">\(\int f(x; \theta) dx\)</span> can be differentiated twice under the integral sign as a function of <span class="math inline">\(\theta\)</span></li>
</ol></li>
<li><strong>Additional regularity conditions</strong>
<ul>
<li>The pdf is at least three times differentiable as a function of <span class="math inline">\(\theta\)</span>. For all <span class="math inline">\(\theta \in \Omega\)</span>, there exist a constant c and a function <span class="math inline">\(M(x)\)</span> such that</li>
</ul></li>
<li><strong>Properties of MLEs</strong>
<ul>
<li>MLEs are asymptotically efficient</li>
<li>MLEs are asymptotically normal</li>
<li>MLEs are asymptotically consistent</li>
</ul></li>
<li><strong>MLEs are asymptotically efficient</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Under regularity conditions, MLEs are asymptotically efficient</li>
<li>This means that the variance of an mle approaches the minimum variance (i.e. CRLB) as sample size increases towards infinity</li>
<li>The efficiency of mles converges to 1 as <span class="math inline">\(n \rightarrow \infty\)</span></li>
</ul></li>
</ul></li>
<li><strong>MLEs are asymptotically normal</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Under certain regularity conditions and correct model specification, MLEs are asymptotically normal</li>
<li>The distribution of <span class="math inline">\(\hat\theta_{mle}\)</span> approaches normal as sample size increases towards infinity</li>
</ul></li>
</ul></li>
<li><strong>MLEs are asymptotically consistent</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Under regularity conditions 1-6, MLEs are asymptotically consistent</li>
<li>This means that MLEs in the sampling distribution converge in probability to the true value of the parameter as sample size increases towards infinity</li>
<li>$ _0 $</li>
</ul></li>
</ul></li>
<li><strong>Variance of an MLE</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The asymptotically consistent estimate of the variance</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Var}(\hat\theta) = \frac{1}{nI(\theta_0)}\)</span></li>
</ul></li>
<li><strong>Estimation</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>As seen, the variance of an MLE is a function of the true population parameter value. However, this is often unknown, the estimate of this value is used instead.</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Var}(\hat\theta) = \frac{1}{nI(\hat\theta)}\)</span></li>
</ul></li>
<li><strong>Asymptotically consistent</strong>
<ul>
<li>This estimate of the variance is asymptotically consistent</li>
<li>It converges in probability to the true variance</li>
<li>$I() I(_0) $</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>SE of an MLE</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \sqrt{\frac{1}{nI(\theta_0)}}\)</span></li>
</ul></li>
<li><strong>Estimation</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \sqrt{\frac{1}{nI(\hat\theta)}}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<div id="section" class="section level10" number="7.0.0.0.0.0.0.0.0.1">
<p class="heading"><span class="header-section-number">7.0.0.0.0.0.0.0.0.1</span> </p>
<p>OTHERS</p>
<ul>
<li><strong>Negative Binomial Distribution</strong>
<ul>
<li><h2 id="concept-1" class="hasAnchor"><strong>Concept</strong><a href="catgorical-outcomes.html#concept-1" class="anchor-section" aria-label="Anchor link to header"></a></h2></li>
</ul></li>
<li><strong>Terms</strong>
<ul>
<li>Complement of an event - The complement of an event is the probability of that event not occurring</li>
</ul></li>
</ul>
<p><strong>Others</strong></p>
<ul>
<li><strong>Score</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><strong>The likelihood function</strong>
<ul>
<li><span class="math inline">\(\displaystyle \mathcal{L}\left( \theta; x \right) = \prod_{i = 1}^{n = 3}{f(x_i; \theta)} = f(x_1; \theta) \times f(x_2; \theta) \times f(x_3; \theta)\)</span></li>
</ul></li>
<li><strong>The log likelihood</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \mathcal{l}(\theta; \textbf{x}) &amp;= \log \mathcal{L}\left( \theta; \textbf{x} \right) \\ &amp;= \log \prod_{i = 1}^{n = 3}{f(x_i; \theta)} \\ &amp;= \log{\left[f(x_1; \theta) \times f(x_2; \theta) \times f(x_3; \theta)\right]} \\ &amp;= \log{f(x_1; \theta)} + \log{f(x_2; \theta)} + \log{f(x_3; \theta)} \end{aligned}\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>The log of the product is sum of the log of each factor in the product</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The score (the first derivative of the log likelihood)</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle S &amp;= \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta} \\ &amp;= \frac{\partial}{\partial\theta}\left[ \log{f(x_1; \theta)} + \log{f(x_2; \theta)} + \log{f(x_3; \theta)} \right] \\ &amp;= \frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta} \end{aligned}\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>The derivative of a sum is the sum of the derivative of each of the elements in the sum</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The expectation of the score</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle E\left(S \right) &amp;= E\left[\frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &amp;= E\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &amp;= E\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + E\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ E\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \end{aligned}\)</span>
<ul>
<li><strong><em>Notes</em></strong>
<ul>
<li>The expectation of a sum is the sum of the expectation of each of the elements in the sum</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The expectation of the score is 0</strong>
<ul>
<li>Since any one of the expectations is 0 (as shown in the one-observation case), the sum of all the expectations is also 0</li>
</ul></li>
</ul></li>
<li><strong>The variance of the score</strong>
<ul>
<li><strong>Mathematics</strong>
<ul>
<li><strong>Variance defined as the second moment about the mean</strong>
<ul>
<li><span class="math inline">\(\begin{aligned} \displaystyle \text{Var}(S) &amp;= \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ \displaystyle &amp;= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &amp;= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + \text{Var}\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ \text{Var}\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] + 2\sum_{j = 1}^{n = 3}{\sum_{i = 1}^{n = 3}{\text{Cov}\left(\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}, \frac{\partial \log{f(x_j; \theta)}}{\partial \theta}\right)}} \end{aligned}\)</span></li>
<li>Assuming that observations are uncorrelated:</li>
<li><span class="math inline">\(\begin{aligned} \displaystyle \text{Var}(S) &amp;= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + \text{Var}\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ \text{Var}\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &amp;= 3\times \text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ &amp;= n\times\text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right]\end{aligned}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Fisher Information</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>The Information from a sample with 3 observations is 3 times the Information from any single observation</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle \text{Var}(S) = \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right]\)</span></li>
<li><span class="math inline">\(\begin{aligned}I_3(\theta) &amp;= 3 \times \text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ I_3(\theta) &amp;= 3 I_1(\theta)\end{aligned}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>The expectation of the score</strong>
<ul>
<li><strong>Concept</strong>
<ul>
<li>Under certain regularity conditions, the expectation of the score evaluated at the true value of <span class="math inline">\(\theta\)</span> is 0</li>
<li>Imagine you know the true value of the parameter, you then take many samples, each time you take a sample, you calculate the score with respect to the true value of the parameter, after doing this for each of the samples, you will have many scores, each coming from each sample, the mean of these scores will be 0, that is, they are clustered around 0</li>
</ul></li>
<li><strong>Mathematics</strong>
<ul>
<li><span class="math inline">\(\displaystyle E(S) = E\left( \frac{\partial f(x_i; \theta)}{\partial \theta}\right) = 0\)</span></li>
</ul></li>
<li><strong>Proof that the expectation of the score is 0</strong>
<ul>
<li><strong>Begin with the identity</strong>
<ul>
<li><span class="math inline">\(\displaystyle 1 = \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~ ~ dx = \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)} ~ dx\)</span></li>
</ul></li>
<li><strong>The first derivative under the integral sign</strong>
<ul>
<li><span class="math inline">\(\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}} ~ dx\)</span></li>
</ul></li>
<li><strong>Which can be reexpressed as</strong>
<ul>
<li><span class="math inline">\(\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx = \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx = E\left[ \frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multivariate-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "night",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/samuel-mak/statistics/edit/master/07-categorical_outcomes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/samuel-mak/statistics/blob/master/07-categorical_outcomes.Rmd",
"text": null
},
"download": ["bookdownproj.pdf", "bookdownproj.epub", "bookdownproj.mobi"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
