# Catgorical outcomes

<p style = "margin-bottom: 0px; font-size: 20px; ">**Analysing Categorical Outcomes**</p>

- **Concept**
  - The process of analysing categorical outcomes 
- **Statistics**
  - Binomial test 
  - Pearson's Chi-squared
  - Cochran-Mantel-Haenszel Chi-squared test 
  - McNemar's test 
  - Fisher's Exact Test
  - Barnard's exact test
  - Boschloo's test 
  - G-test 
  - Cram√©r's V


- **Pearson's Chi-squared test (Pearson, 1900)**
  - **Concept**
    - A statistical test that tests the null hypothesis that 2 categorical variables are independent 
    - Test of independence between 2 categorical variable is like a test of homogeneity of conditional distributions 
      - For example, if factor A and factor B are independent, then the conditional probabilities are homogeneous ($P(\text{Married once} | \text{College}) = P( \text{Married once}| \text{No College})$)
    - **Conceptual Hypotheses**
      - **Null Hypothesis**
        - The two categorical variables are independent 
      - **Alternative Hypothesis**
        - The two categorical variables are not independent (they are associated)
  - **The probability of each cell under the null hypothesis**
    - **Concept**
      - The probability of each joint-category under the null hypothesis 
    - **Mathematics**
      - $\pi_{ij} = \pi_{i\cdot} \pi_{\cdot j}$
    - **Estimation**
      - **Concept**
        - The maximum likelihood estimation of the population probability of each of the joint-categories 
      - **Mathematics**
        - $\displaystyle \hat{\pi}_{ij} = \hat\pi_{i\cdot} \hat\pi_{\cdot j} = \frac{n_{i \cdot}}{n} \times \frac{n_{\cdot j}}{n} = \frac{n_{i \cdot} n_{\cdot j}}{n^2}$
          - ***Where***
            - $n_{i\cdot}$ - The number of observations in the $i$^th^ row
            - $n_{\cdot j}$ - The number of observations in the $j$^th^ column 
            - $n$ - The total sample size
  - **The expected number of observations**
    - **Concept**
      - The number of observations in each of the K joint-categories under the null hypothesis that the 2 categorical variables are independent 
    - **Mathematics**
      - $\displaystyle E(n_{ij}) = n\hat{\pi}_{ij} = n\frac{n_{i \cdot} n_{\cdot j}}{n^2} = \frac{n_{i \cdot} n_{\cdot j}}{n}$
  - **Pearson's Chi-squared statistic**
    - **Concept**
      - The sum of the standardised squared deviations of the observed number of observations and the expected number of observations under the null hypothesis of each of the K joint-categories 
    - **Mathematics**
      - $\begin{aligned} \displaystyle \chi^2 &= \sum_{i = 1}^{I}{\sum_{j = 1}^{J}{\frac{\left[ n_{ij} - E(n_{ij})\right]^2}{E(n_{ij})}}} \\ \displaystyle &= \sum_{i = 1}^{I}{\sum_{j = 1}^{J}{\frac{\left( n_{ij} - \frac{n_{i\cdot} n_{\cdot j}}{n}\right)^2}{\frac{n_{i\cdot} n_{\cdot j}}{n}}}} \end{aligned}$
        - ***Where***
          - $n_{ij}$ - The observed number of observations in joint-category $ij$
          - $E(n_{jk}$ - The expected number of observations in joint-category $ij$ under the null hypothesis
          - $\left( n_{ij} - \frac{n_{i\cdot} n_{\cdot j}}{n}\right)^2$ - The squared deviation for for joint-category $ij$
    - **Degrees of freedom (NOT ENTIRELY SURE)**
      - **Concept**
        - The degrees of freedom under the null hypothesis is the number of joint-categories minus the number of independent linear restrictions placed on the cell probabilities 
        - Although the calculation of the number of degrees of freedom depends on the application of the Chi-squared test, the general principle is that the appropriate number of degrees of freedom will equal the number of joint-categories minus 1 df for each independent linear restriction placed on the cell probabilities. In some applications, other restrictions may also be introduced because of the necessity for estimating unkown parameters required in the calculation of the expected cell frequencies or because of the method used to collect the sample 
        - There is always one linear restriction in each cell because the sum of the cell probabilities must equal 1 ($p_1 + p_2 + p_3 + \cdots + p_k = 1$)
      - **Mathematics**
        - $df = IJ - 1 - (I-1) - (J-1) = (I-1)(J-1)$
          - ***Note***
            - The equation shows that df is the total number of joint-categories ($IJ$) minus the number of restrictions in the $I$ rows, minus the number of restrictions in the $J$ columns, and minus the number of restrictions in all the cells as a whole (minus the 1) (NOT ENTIRELY SURE)
      - **Introduction**
        - The calculation of the number of degrees of freedom depends on the application of the Chi-squared test 
        - The general principle is that the appropriate number of degrees of freedom will equal the number of cells, k, less 1 df for each independent linear restriction placed on the cell probabilities 
        - There is always one linear restriction in each cell because the sum of the cell probabilities must equal 1 ($p_1 + p_2 + p_3 + \cdots + p_k = 1$)
    - **Distribution of the Chi-squared statistic**
      - **Concept**
        - $X^2$ tends towards a chi-squared distribution as n increases (it can be shown)
        - The square root of the chi-squared statistic is a normal random variable (normally distributed)
        - The square of a normal random variable has a chi-squared distribution 
        - Hence, the chi-squared statistic has a chi-square distribution 
      - **Mathematics**
        - $X^2 \sim \chi$
    - **NHST**
      - **Concept**
        - Tests the probability of having a Chi-squared statistic equal to or larger than the observed Chi-squared statistic in the Chi-square distribution under the null hypothesis 
      - **Hypotheses**
        - $H_0: \pi_{ij} = \pi_{i \cdot}\pi_{\cdot j}, ~~~~~ \text{for} ~ i = 1:I, j = 1:J$
  - **Some caveats**
    - **Number of cell counts**
      - There is a rule of thumb that it is all expected cell counts are required to be at least 5. 
      - Although Cochran (1952) noted that his can be as low as one for some situations

        
 
- **Odds Ratio**
  - **Odds**
    - **Concept**
      - The ratio of the probability of an event occurring to the probability of the event not occurring 
    - **Mathematics**
      - $\displaystyle Odds(\text{event}) = \frac{P(\text{event})}{1 - P(\text{event})}$
    - **Conditional Odds**
      - **Concept**
        - The ratio of the probability of an event occurring given a value/level of another categorical variable to the probability of it not occurring 
      - **Mathematics**
        - $\displaystyle Odds(A | x) = \frac{P(A | x)}{1 - (A | x)}$
  - **The Odds Ratio**  
    - **Concept**
      - The ratio of the odds of an event given a value of a categorical variable and the odds of the same event given another value of the same categorical variable 
      - This ratio tells the influence of the level of the second categorical variable in the numerator have on the probability of the event of interest
    - **Mathematics**
      - $\displaystyle OR(A) = \frac{Odds(A|x_1)}{Odds{(A|x_2)}}$
        
        
        
- **Bernoulli Trails**
  - **Concept**
    - A Bernoulli trial is a random independent experiment with 2 possible outcomes (usually referred to as "success" or "failure") and the probability of the "success" event ($\pi$) is the same every time the experiment is conducted (identical trials) and the outcome of each of the trials does not influence the outcome of other trials (independent trials; sampling with replacement) 
    - $y_i$ - The outcome of Bernoulli trial $i$ in the sequence of $n$ trials - 1 indicates that the "success" event had occurred and 0 indicates that the "failure" event had occurred in trial $i$
    - $y$ - The total number of "success" events in a sequence of $n$ trials - $y = \sum_{i = 1}^{n}{y_i}$
    - $y$ is treated as an independent random variable that can vary between the 2 possible outcomes (the "success" event or the "failure" event)
    - Bernoulli process - When there is a sequence of Bernoulli trials 
    - $p= 1-q$
    - $p$ - The probability of event occurring 
    - $q$ - The probability of the event not occurring
    
<p style = "margin-bottom: 0px; font-size: 20px; ">**Binomial Distribution**</p>

- **Binomial Distribution**
  - **Concept**
    - A special case of the multinomial distribution when the number of trials $K = 2$
    - A discrete probability distribution for the discrete independent random variable ($y$) of the number of the "success" events in a sequence of a fixed/finite $n$ number of Bernoulli trials/experiments (independent, identical) (the x-axis represents the number of successes; the y-axis represents the probability)
    - (if trials are not independent or identical, $y$ will not follow a binomial distribution, they will follow other distributions; e.g. hypergeometric distribution is for the case when trials are not independent; specifically, it samples without replacement)
    - A Bernoulli distribution is a special case of the binomial distribution where $n = 1$
    - The binomial distribution has 2 parameters, $n$, the number of Bernoulli experiments in the sequence, and $\pi$, the probability of each of the numbers of "success" events 
    - An independent random variable ($y$) that has an approximate binomial distribution is denoted as $y \sim B(n, \pi)$
  - **Binomial probability mass function**
    - **Concept**
      - The probability mass function for the binomial distribution
    - **Mathematics**
      - $P(y) = {n\choose y} \pi^y (1 - \pi)^{n - y} ~~~, y = 0:n$
        - ***Notes***
          - ${n\choose y}$ - The binomial coefficient 
  - **Parameters of the binomial distribution**
    - **Mean**
      - **Mathematics**
        - $\mu = \text{E}(y) = n\pi$
    - **Variance**
      - **Mathematics**
        - $\sigma^2 = n\pi(1-\pi)$
    - **Characteristics of the binomial distribution**
      - **$\pi$ and Skewness (biasedness)**
        - **Concept**
          - The binomial is symmetric when $\pi = 0.50$ regardless of $n$ 
          - The binomial distribution becomes more positively skewed as $\pi$ decreases from $0.50$ towards 0
          - The binomial distribution becomes more negatively skewed as $\pi$ increases from $0.50$ towards 1
        - **Mathematics**
          - The skewness is described by the following equality:
          - $\displaystyle \frac{\text{E}(y-\mu)^3}{\sigma^3} = \frac{1-2\pi}{\sqrt{n\pi(1 - \pi)}}$
      - **$n$ and normality**
        - **Concept**
          - The binomial distribution converges to normality as $n$ increases
          - For fixed $\pi$, the binomial distribution can be reasonably assumed to be normal when $n[\min(\pi, 1‚Äì\pi)]$ is as small as about 5 (Agresti, 2013, p.5)

- **Statistical Inference with the Binomial distribution (Not developed)**
  - **Wald test**
    - **Concept**
      - A test statistic in which the standard error nonnull estimated (not the standard error of population distribution under the null hypothesis)
    - **The Wald statistic for probability**    
      - **Mathematics**
        - $\displaystyle W = \frac{(p - \pi)^2}{Var(p_i)} $
    - **The Wald z statistic**
      - $\displaystyle z_W = \frac{p - \pi}{SE} = \frac{p - \pi}{\frac{\sqrt{\hat\pi(1 - \hat\pi)}}{n}}$



- **Multinomial distribution**
  - **Concept**
    - A discrete probability distribution for the discrete independent random variable ($y$) of the combination of numbers with each number being the number of occurrence of each of the multiple possible outcomes in a sequence of a fixed/finite $n$ number of random independent and identical trial/experiment 
    - The categorical distribution is a special case of the multinomial distribution where $n = 1$
    - The probability of obtaining a combination of $n_1, n_2, \cdots, n_k$ is denoted as $\text{P}(n_1, n_2, \cdots, n_k)$ where $n_k$ is the number of occurrence for outcome $k$ in a sequence of $n$ random, independent, and identical trials 
    - <details> <summary> Alternative text </summary> In 1 trial, there are multiple (but fixed) number of possible outcomes, the outcome of a trial is represented by a combination (e.g. if there are 4 possible outcomes, the combination could be 0, 1, 0, 0, meaning that the outcome for this trial is category 2). Now imagine we have $16$ of this trial, the combination could be something like 4, 4, 4, 4. The multinomial distribution models the probability of getting different combinations. In the case of 4, 4, 4, 4, this is a fair trial (the null hypothesis), where each of the categories have equal chance of occurrence, so this combination after $16$ trials would be the most probable (it has a probability of 0.50), whereas a combination of something like 6, 5, 3, 2 would be less probable in the null multinomial distribution </details>
    - **The outcome of a single multinomial trial ($y_i$)**
      - **Concept**
        - The outcome of a single random, independent and identical multinomial trial 
        - The outcome can be one of multiple but fixed number of possible outcomes 
      - **Mathematics**
        - $y_i = (y_{i,1}, y_{i,2}, \cdots , y_{i,k})$
          - ***Where***
            - $k$ - The number of possible outcomes of a single trial 
    - **The outcome of a sequence of $n$ multinomial trials**
      - **Concept**
        - The number of occurrence of each of the $k$ outcomes after a sequence of $n$ random, independent, and identical trials 
        - This is represented as a combination of $k$ numbers with each number representing the number of occurrence of each of the $k$ outcomes after a sequence of $n$ random, independent, and identical trials
      - **Mathematics**
        - $y = (n_1, n_2, \cdots , n_k)$
  - **Multinomial probability mass function**
    - **Concept**
      - A function that models the probability of each of all possible outcome combinations 
      - The multinomial distribution has $K - 1$ dimensions because $y_{i,k}$ is linearly dependent on the others and therefore is redundant
    - **Mathematics**
      - $\displaystyle \text{P}(n_1, n_2, \cdots , n_{k-1}) = \left( \frac{n!}{\Pi_{k = 1}^{K}{n_k!}} \right) \Pi_{k = 1}^{K}{\pi_{k}^{n_k}}$
  - **Parameters of a multinomial distribution**
    - **Expectation**
      - **Mathematics**
        - $E(n_j) = n\pi_j$
    - **Variance**
      - **Mathematics**
        - $\sigma^2_{n_j} = n\pi_j(1-\pi_j)$
    - **Covariance between any two outcomes**
      - **Mathematics**
        - $\text{Cov}(n_j, n_k) = -n\pi_j\pi_k$
  
- **Poisson distribution**
  - **History**
    - Introduced by Poisson (1781 - 1840) and published with his probability theory in his work Recherches sur la probabilit√© des judgements en mati√© criminelle et en mati√©re civile (1837) where he theorised about the number of wrongful convictions in a given country by fousing on certain random variables N that count the number of discrete occurrenses that take place during a time-interval of given length 
    - Newcomb (1860) applied the Poisson distribution to estimate the distribution of the number of stars found in a unit of space
    - Bortkiewicz (1898) applied the Poisson distribution to estimate the number of soldiers in the Prussian army killed accidentally by horse kicks (this experiment introduced the Poisson distribution to the field of reliability engineering)
  - **Concept**
    - A discrete probability distribution of the discrete independent random variable ($y$) of the number of the "success" events in a sequence of an infinite number of Bernoulli trials/experiments (independent, identical) within a fixed time interval and space 
    - The Poisson distribution is used for the number of events that occur randomly over a fixed window of time or space when outcomes in disjoint periods or regions are independent 
    - The Poisson distribution can be used for the binomial case when $n$ is larger and $\pi$ is small (then $\mu = n\pi$)
    - The Poisson distribution is conceptually similar to the binomial distribution, the difference is that the binomial distribution has a fixed number of trials ($n$), meanwhile, the Poisson distribution has an infinite number of trials (an infinite population of trials)
  - **Poisson probability mass function**
    - **Mathematics**
      - $\displaystyle \text{P}(y) = \frac{e^{-\mu}\mu^{y}}{y!}~~~ y = 0:.$ 
        - ***Where***
          - $y$ - The number of times an event occurred (sometimes it is denoted as $k$)
          - $\mu$ - The expected number of times an event occurred (sometimes it is denoted as $\lambda$)
        - ***Notes**
          - Sometimes it is expressed as such 
    - **Mean of the Poisson PMF**
      - **Concept**
        - The number of occurrence of an event in the null Poisson distribution
      - **Mathematics**
        - $\mu = \text{E}(y_i) = \lambda$
    - **Mode of the Poisson distribution**
      - **Concept**
        - The mode equals to the integer part of $\mu$
    - **Variance of the Poisson PMF**
      - **Concept**
        - The variance of the Poisson PMF is the same as its mean 
      - **Mathematics**
        - $\text{Var}(y_i) = \text{E}(y_i)$
    - **Skewness**
      - The Poisson distribution approaches normal as $\mu$ increases (when $\mu$ is at least 10 it can be assumed to be normal)
      - **Mathematics**
        - The skewness is described by the following equality
        - $\displaystyle \frac{\text{E}(y - \mu)^3}{\sigma^3} = \frac{1}{\sqrt{\mu}}$


- **Binomial and Poission distribution and the problem of Overdispersion**
  - **Concept**
    - Modelling count observations with binomial or Poission distributions often result in overdispersion. 
    - $\mu$ can vary because of unmeasured factor
    - Unconditionally, 
      - The Expectation is 
        - $E(y) = E[E(y | \mu)]$
      - The variance is 
        - $\text{Var}(y) = E[\text{Var}(y|\mu)] + \text{Var}[E(y|\mu)]$
        

        
- **Overdispersion**
  - **Concept**
    - The phenomenon in which the observed variability in the real world is larger than the variability predicted by the statistical model
    - This may cause inaccurate inferences 
    - Overdispersion is a common feature because in practice populations are frequently heterogeneous 
    - Count observations using the binomial or Poission distribution often encounter this problem 


    
    
    
<p style = "margin-bottom: 0px; font-size: 20px; ">**Likelihood**</p>

- **Likelihood**
  - **Concept**
    - The probability of the observed sample data/datum as a function of the parameters of the chosen statistical model/distribution
    - In the case of data (when there are multiple observations), it is the joint probability between the observations under the statistical model/distribution given the values of the parameters of the statistical model/distribution
  - **Related terms**
    - **Kernel** - The part of a likelihood function that involves the model parameters (the relevant part of the likelihood function)
  - **Mathematics**
    - $\displaystyle \mathcal{L}(\theta | X) = \text{PF}(x_i)$
      - ***Where***
        - $\theta$ - The parameter of the chosen statistical model 
        - $X$ - The observed sample data 
      - ***Notes***
        - It can also be written as $\text{P}(X | \theta)$, but this is less commonly used
        
        
        
        
        
        
        
        
        
        
        
- **The Likelihood Function (of a random sample)**
  - **Concept**
    - A function that describes the likelihood of a random sample data/datum as a function of the values of the parameters of the chosen statistical model
    - It is the joint probability of the observations at different values of the parameter of the model 
    - In other words, it describes the probability of getting the sample data/datum given certain values of the parameters of the statistical model
    - It treats the sample data/datum as given and parameters as variables 
    - The resulting graph of the likelihood function can be visualised through a plot with likelihood against the values of the parameter(s) of the chosen statistical model (although the graph is concave for most statistical models, it can vary between statistical models and is not necessarily concave)
  - **Mathematics**
    - $\displaystyle \mathcal{L}(\theta; \mathbf{x}) = \prod_{i = 1}^{n}{f(x_i; \theta)} $
      - ***Where***
        - $f(x_i; \theta)$ - The probability density function (PDF) for the variable of interest (in this example here the statistical model has only one parameter, $\theta$, when it has two parameters, let's say $\sigma^2$, then it is expressed as $f(x_i; \theta, \sigma^2)$)
        - $\mathbf{x} = (x_1, x_2, x_3, \cdots , x_n)'$ - A vector of observed random variable/data 
      - ***Notes***
        - $\mathcal{L}(\theta; \mathbf{x})$ is sometimes denoted as $\mathcal{L}(\theta)$
  - **The Log Likelihood Function**
    - **Concept**
      - The log of the likelihood function (or likelihood)
      - The log likelihood function is often used instead of the likelihood function because it is more convenient to use and it simplifies many of the subsequent calculations because the log of the product is the sum of the log and calculations are easier with sum rather than with products 
      - No information is lost from logging the likelihood because the log is a one-to-one function
      - Since the log is a strictly increasing function, the values of the model parameters that maximise $\mathcal{l}(\theta; \text{x})$ are the same as the values that maximise $\mathcal{L}(\theta; \mathbf{x})$
    - **Mathematics**
      - $\displaystyle \mathcal{l}(\theta; \text{x})=\log{\mathcal{L}(\theta; \text{x})}$
    - **The log of a product is the sum of the log**
      - $\displaystyle \log\prod_{i = 1}^{n}{f(x_i; \theta)} = \sum_{i = 1}^{n}{\log f(x_i; \theta)}$
      - ***Notes***  
        - $\mathcal{l}(\theta; \mathbf{X})$ can be denoted as $\mathcal{l}(\theta)$

        
        
<p style = "margin-bottom: 0px; font-size: 20px; ">**Maximum Likelihood Estimation**</p>

- **Maximum Likelihood Estimation**
  - **Concept**
    - A model parameter estimation method in which the parameters are estimated by finding the parameters of the statistical model that maximizes the likelihood of the sample data 
    - This is done by finding the maximum (if there exists) of the graph of the partial derivative of the likelihood function of the sample data 
    - If the graph of the partial derivative of the likelihood function of the sample data is concave, there will only be one maximum, and 
  - **Mathematics**
    - $\hat\theta_{mle} = Argmax\mathcal{L}(\theta; \mathbf{X})$
      - ***Where***
        - $Argmax\mathcal{L}(\theta; \mathbf{X})$ - This notation means that $\mathcal{L}(\theta; \mathbf{X})$ achieves its maximum value at $\hat\theta$ - The value of $\theta$ with the maximum likelihood 
  - **Methods**
    - **Concept**
      - The exact method can vary and depend on the properties of the pdf/likelihood function
    - **First Derivative of the likelihood function**
      - **Concept**
        - The value of the parameter(s) is found by equating the first derivative of the likelihood function of the sample data to zero and then solving for the parameter(s)
        - If there are multiple parameters (i.e. a multivariable function), multivariable calculus techniques, such as partial differentiation, are used (in partial differentiation, each of the partial derivative for each of the parameters is set to 0 and each of the parameters are solved)
      - **Mathematics**
        - $\displaystyle \frac{\partial\mathcal{L}(\theta)}{\partial \theta} = 0$
      - ***Notes***
        - This is an estimating equation (EE), an equation for estimating the population parameters
  
- **Properties of the MLEs (THIS SECTION IS NOT DEVELOPED)**
  - **The Invariance Property of MLE**
    - **Concept**
      - If the parameter of interest $\eta$ is some function ($g(.)$) of another parameter $\theta$ ($g(\theta)$), that is $\eta = g(\theta)$, then the $g(.)$ function of the mle of $\theta$ ($g(\hat\theta_{mle})$) is the mle of $\eta$ (I find the mathematical definition below is better for understanding)
    - **Mathematics**
      - If $\eta = g(\theta)$, then $\hat\eta_{mle} = g(\hat\theta_{mle})$
        - ***Where***
          - $g()$ is some kind of function




         
- **The Score**
  - **Concept**
    - The score is the slope of the log-likelihood function evaluated at a particular value of the parameter
- **The Score at the true value of the parameter**
  - **Concept**
    - The slope of the likelihood function evaluated at the true value of the parameter ($\theta$)
    - The score is a variable because it is subject to sampling variation - That is, the score derived from a samples can be different from the scores derived from other samples 
    - In reality, we will never know this because the true value of the population parameter is unknown
  - **A single observation case**
    - **The score**
      - **Mathematics**
        - **The likelihood function**
          - $\begin{aligned}\displaystyle \mathcal{L}\left( \theta; x \right) &= \prod_{i = 1}^{n = 1}{f(x_i; \theta)} \\ &= f(x; \theta) \end{aligned}$
        - **The log likelihood**
          - $\begin{aligned} \displaystyle \mathcal{l}(\theta; x) &= \log\mathcal{L}\left( \theta; x \right) \\ &= \log f(x; \theta) \end{aligned}$
        - **The score (first derivative of the log likelihood evaluated at the true value of the parameter)**  
          - $\begin{aligned}S_\theta &= \displaystyle \frac{\partial \mathcal{l}(\theta; x)}{\partial \theta} \\ &= \frac{\partial \log f(x_i; \theta)}{\partial \theta} \end{aligned}$
    - **The expectation of the Score**
      - **Mathematics**
        - $\displaystyle E(S_\theta) = E\left( \frac{\partial \log f(x_i; \theta)}{\partial \theta}\right)$
      - **The expectation of the score is 0**
        - **Concept**
          - The mean of the scores all with a single observation and evaluated at the true value of the parameter is 0
        - **Mathematics**
          - $\displaystyle E(S_\theta) = E\left( \frac{\partial \log f(x_i; \theta)}{\partial \theta}\right) = 0$
        - **Proof**
          - **Begin with the identity**
            - $\displaystyle 1 = \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~  ~ dx = \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)}  ~ dx$
          - **The first derivative under the integral sign**
            - $\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}}  ~ dx$
          - **Reversing the chain rule for log** 
            - $\begin{aligned}\displaystyle 0 &= \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx \\ &= \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx \end{aligned}$
              - ***Reminder***
                - **The chain rule for log**
                  - $\begin{aligned}y &= \log{(g(x))} \\ \displaystyle \frac{dy}{dx} &= \frac{1}{g(x)} \times g'(x) \end{aligned}$
                - **Hence**
                  - $\begin{aligned} \displaystyle \int_{-\infty}^{\infty}{\frac{\partial \log{f(x ;\theta)}}{\partial \theta} \times f(x; \theta) ~ dx} &= \displaystyle \int_{-\infty}^{\infty}{\frac{1}{f(x; \theta)} \times f'(x; \theta) \times f(x; \theta) ~ dx} \\ &= \displaystyle \int_{-\infty}^{\infty}{\frac{1}{f(x; \theta)} \times \frac{\partial f(x; \theta)}{\partial \theta} \times f(x; \theta) ~ dx} \\ &= \displaystyle \int_{-\infty}^{\infty}{\frac{\partial f(x; \theta)}{\partial \theta f(x; \theta)} \times f(x; \theta) ~ dx} \end{aligned}$
                  - In the derivation above, it utilises this rule but in the reversed order
          - **Expressed as expectation**
            - $\displaystyle 0 = E\left[ \frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right]$
    - **The variance of the score**
      - **Concept** 
        - The sampling variation of the scores given the true value of $\theta$ (alternatively speaking, it is the variation of the scores evaluated at the true value of $\theta$ due to sampling error)
      - **Variance defined as the second moment about the mean**
        - **Concept**   
          - The variance can be defined as the second moment about the mean
        - **Mathematics**
          - $\displaystyle \text{Var}(S) = \text{E}\left[ \left(\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right)^2\right]$
      - **Variance defined as the negative of the expectation of the second derivative of the likelihood function**
        - **Concept**   
          - Through derivations, it can be shown that the variance equals to the negative of the expectation of the second derivative of the likelihood function evaluated at the true value of the parameter. In other words, it is the average curvature of the likelihood functions at the true value of the parameter in the parameter space. 
          - **Mathematics**
            - **Begin with the identity (this is seen before in the expectation section)**
            - $\begin{aligned}\displaystyle 1 &= \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~  ~ dx \\ &= \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)}  ~ dx \end{aligned}$
            - **The first derivative under the integral sign (this is seen before in the expectation section)**
              - $\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}}  ~ dx$
            - **Which can be reexpressed as (this is seen before in the expectation section)** 
              - $\begin{aligned}\displaystyle 0 &= \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx \\ &= \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx \end{aligned}$
            - **Differentiate again (the second derivative)**
              - $\begin{aligned}\displaystyle 0 &= \int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx + \int_{-\infty}^{\infty}{\frac{\partial \log f(x; \theta)}{\partial \theta} \frac{\partial \log f(x; \theta)}{\partial \theta} ~ f(x; \theta) ~ dx} \\ \displaystyle 0 &= \int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx + \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2} ~ f(x; \theta)~dx\\ \displaystyle -\int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx &= \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2}~ f(x; \theta)~dx \end{aligned}$
            - **Expressed as expectations**
              - $\displaystyle -\int_{-\infty}^{\infty}{\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}} ~ f(x; \theta)~dx = \int_{-\infty}^{\infty}{\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2}~ f(x; \theta)~dx \\ \displaystyle -E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right) = E\left[\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2\right]$
            - Hence, you can see that the second moment about the mean ($E\left[\left(\frac{\partial \log f(x; \theta)}{\partial \theta}\right)^2\right]$) equals to the negative of the expectation of the curvature of the likelihood function evaluated at the true value of the parameter ($-E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right)$)
      - **Which expression is preferred?**
        - Usually the second definition of the variance is preferred as it is usually easier to compute than the first definition
        
&nbsp
    - **Fisher Information**
      - **Concept (general)**
        - A quantity that quantifies the amount of information that a sample of size $n = 1$ carries about an unknown parameter of a statistical model of that random variable 
      - **Mathematics**
        - $\begin{aligned}\displaystyle I_1(\theta) &= \text{Var}(S) \\ \displaystyle &= \text{Var}\left[\frac{\partial \mathcal{l}(\theta; x)}{\partial \theta} \right] \\ \displaystyle  &= \text{Var}\left[\frac{\partial \log f(x_i; \theta)}{\partial \theta}\right] \end{aligned}$
          - ***Notes***   
            - $I_1(\theta)$ - Usually it is expressed as $I(\theta)$ but I expressed it as such to emphasise that it is the Information from one observation 
      - **Information defined as the second moment of about the mean**
        - **Concept**
          - As seen, the variance of the score can be defined in terms of the second moment of about the mean, since the Fisher Information is the variance of the score at the true value of the parameter, the Fisher Information can be interpreted the same way 
      - **Information defined as the curvature**
        - **Concept**
          - As seen, the variance of the score can be defined in terms of the curvature of the likelihood function at the true value of the parameter, which means that Fisher information can be interpreted as the same way, which is pretty intuitive 
          - Information can be expressed in terms of the negative of the expectation of the curvature of the likelihood function evaluated at the true value of the parameter
          - Hence, the greater the curvature of the likelihood function at the true value of the parameter, the more information the data/datum has about the unknown parameters of the model (in the extreme case when the likelihood function is at the highest at a single value of the parameter and 0 at all other values of the parameter, in other words, the likelihood is non-zero at a single point in the parameter space, the data/datum contains complete information about the parameter)
          - The smaller the curvature of the likelihood function at the true value of the parameter, the less information the data has about the unknown parameters of the model (in the extreme case when the likelihood function is flat, that is, when the likelihood is the same across values of the parameter, then the data/datum contains no information at all about the value of the parameter)
      - **Mathematics**
        - $\begin{aligned}\displaystyle I(\theta) &= \text{Var}(S) \\ &= -E\left(\frac{\partial^2 \log f(x; \theta)}{\partial \theta^2}\right)\end{aligned}$
        
  - **A multiple-observation case**
    - **Score**
      - **Mathematics**
        - **The likelihood function**
          - $\displaystyle \mathcal{L}(\theta; \mathbf{X}) = \prod_{i = 1}^{n}{f(x; \theta)}$
        - **The log likelihood function**
          - $\displaystyle \mathcal{l}(\theta; X) = \log{\mathcal{L}(\theta; X)} = \sum_{i = 1}^{n}{\log{f(x; \theta)}}$
            - ***Notes***
              - The log of a product is the sum of the log of each factor in the product
        - **The Score (the first derivative of the log likelihood function) (NOT SURE ABOUT THIS)**
          - $\begin{aligned} \displaystyle S_n &= \frac{\partial \mathcal{l}(\theta; X) }{\partial \theta} \\ \displaystyle &= \frac{\partial }{\partial \theta} \mathcal{l}(\theta; X) \\ \displaystyle &= \frac{\partial}{\partial \theta} \sum_{i = 1}^{n}{\log{f(x; \theta)}} \\ \displaystyle  &= \sum_{i = 1}^{n}{\frac{\partial}{\partial \theta}\log{f(x; \theta)}} \\ \displaystyle &= \sum_{i = 1}^{n}{\frac{\partial \log{f(x; \theta)}}{\partial \theta}} \\  \displaystyle &= \sum_{i = 1}^{n}{S_1} \\ &= nS_1 \end{aligned}$
            - ***Note***
              - **The sum rule of differentiation** - The derivative of a sum is the sum of the derivative
    - **Expectation of the Score**
      - **Mathematics**
        - $\begin{aligned}\displaystyle \text{E}(S_n) &= \text{E}\left[\frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &= \text{E}\left[ \sum_{i = 1}^{n}{\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}}\right]\\ &= \sum_{i = 1}^{n}{\text{E}\left[ \frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right]} \end{aligned}$ 
        - The expectation of the score is 0, hence:
        - $\begin{aligned} \text{E}(S_n) &= \sum_{i = 1}^{n}{0} \\ &= 0\end{aligned}$
    - **Variance of the score**
      - **Variance defined as the second moment about the mean**
        - **Concept**
          - The variance of the score in a sample with n observations is n times the information of any one observation in the sample 
        - **Mathematics**
          - $\begin{aligned} \displaystyle \text{Var}(S) &= \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &= \text{Var}\left[\sum_{i = 1}^{n}{\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}}\right] \\ &= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta}\right]} + \sum_{j = 1}^{J}{\sum_{i = 1}^{I}{\text{Cov}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta} \frac{\partial \log{f(x_j; \theta)}}{\partial \theta}\right]}} \end{aligned}$
            - ***Notes***
              - **Bienaym√©'s identity**
                - **Concept**
                  - The variance of the sum is the sum of the variance of each of the elements plus the sum of the covariance of each pair of the elements
                  - If the random variables are uncorrelated, that is, they have a covariance of 0, then it implies that the variance of the sum is the sum of the variance of the elements
                - **Mathematics**
                  - $ \text{Var}(\sum_{i = 1}^{n}{x_i}) = \sum_{i = 1}^{n}{\text{Var}\left(x_i\right)} + \sum_{j = 1}^{J}{\sum_{i = 1}^{I}{\text{Cov}\left( x_i, x_j\right)}} $
          - **Assuming that the scores are uncorrelated (having a correlation of 0)**
          - $\begin{aligned}\displaystyle \text{Var}\left(S_n\right) &= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x_i; \theta)}}{\partial \theta}\right]} \\ &= \sum_{i = 1}^{n}{\text{Var}\left[ \frac{\partial \log{f(x; \theta)}}{\partial \theta}\right]} \\ &= n\times\text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ &= n\text{Var}(S_1)\end{aligned}$
    - **Fisher Information**
      - **Concept**
        - The Information in a sample with n observations is n times the Information from any one observation in the sample 
      - **Mathematics**
        - $\begin{aligned}\displaystyle \text{Var}\left(S_n\right) &= n\text{Var}(S_1) \\ I_n(\theta) &= nI_1(\theta)\end{aligned}$
        
    - **Sample Estimation of the variance**
      - **Concept**
        - The Fisher information can be estimated from the sample because it can be shown that $I(\hat\theta_{n}) \xrightarrow{P} I(\theta_{0})$
    - **Variance of mle**
      - **Mathematics**
        - $\displaystyle \sigma_{\hat\theta}^{2} = \frac{1}{nI(\hat\theta)}$
        
    - **Confidence interval**
      - **Mathematics**
        - $\displaystyle \left( \hat\theta_n - z_{\alpha/2} \frac{1}{\sqrt{nI(\hat\theta)}}, \hat\theta_n + z_{\alpha/2} \frac{1}{\sqrt{nI(\hat\theta)}} \right)$

- **Closed form issue**
  - **Concept**
    - In some (most) cases, the solution of the estimating equation $\displaystyle \frac{\partial \mathcal{L}(\theta; \mathbf{X}) }{\partial \theta} = 0$ cannot be obtained in closed form. In situations like this, numerical methods are used to find the solution 
  - **Newton-Raphson method**
    - **Concept**
      - The following mathematics is the general Newton-Raphson method applied to MLE. The general Newton-Raphson method description is available in the maths section
    - **Mathematics**
      - $\displaystyle \hat\theta_{}^{(1)} = \hat\theta_{}^{(0)} - \frac{\mathcal{L}'(\hat\theta_{}^{(0)}; \mathbf{X})}{\mathcal{L}''(\hat\theta_{}^{(0)}; \mathbf{X})}$
    - **Some interesting stuff**
      - Each of the k-step estimators is an asymptotically efficient estimate of $\theta$ given its previous estimate is a consistent estimator of $\theta$
  - **Newton's method** 
    - **Concept**
      - An iterative method for estimating the root/solution of a function (an expression that equates to 0) 
      It can be used to approximate the root\solution of a non-closed form mathematical expression that equates to 0
      - This method has rapid quadratic convergence rate 
      - Start with an initial estimate ($x_0$). Then create a tangent line on the function at the value of that estimate ($f(x_0)$), the x-intercept of that tangent line will become the one-step estimate (a new estimate; and this is typically closer to the true value than the initial estimate). That is one iteration. Then for the second iteration, do the same thing again but with $x_1$ as the starting estimate. That is, create a tangent line on the function at $x_1$. The x-intercept of that tangent line will become the second-step estimate. That is now two iterations. Repeat this process until some kind of convergence criterion/criteria is reached. (Convergence is seen when the estimates tend towards some range of values)
    - **Mathematics**
      - $\displaystyle x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$
    - **Procedure**
      - **Start with a close initial guess at the solution**
        - Let $\hat\theta^{(0)}$ be the initial guess 
      - **First iteration: producing the one-step estimate**
        - $\displaystyle \hat\theta^{(1)} = \hat\theta^{(0)} - \frac{\mathcal{L}'(\hat\theta^{(0)}; \mathbf{X})}{\mathcal{L}''(\hat\theta^{(0)}; \mathbf{X})}$
      - **Second iteration: producing the second-step estimate**
        - $\displaystyle \hat\theta^{(2)} = \hat\theta^{(1)} - \frac{\mathcal{L}'(\hat\theta^{(1)}; \mathbf{X})}{\mathcal{L}''(\hat\theta^{(1)}; \mathbf{X})}$
      - **Iterate the process until convergent criteria is reached**
    - **Mathematical Explanation**
      - **Start with an initial estimate**
        - Let $x_0$ be an initial estimate
      - **First iteration: Producing the one-step estimate**
        - Produce a tangent line on the curve at the value of the initial estimate ($x_0$)
        - The tangent line will cross the x-axis 
        - The point on the x-axis that the tangent cross (which is the x-intercept of the tangent line) is the one-step estimate, which is another estimate. Typically, this estimate is closer to the true value than the initial estimate.
        - **Find the x-intercept**
          - The x-intercept is found by subtracting the initial estimate by the distance between the initial estimate and the new estimate on the x-axis. 
          - Let $k$ be the distance between the initial estimate and the new estimate on the x-axis
          - $x_1 = x_0 - k$
          - **Find k**
            - $\tan(\theta) = \frac{f(x_0)}{k}$
            - Since $\tan(\theta)$ can be described by $\frac{dy}{dx}= \frac{df(x_0)}{k} = f'(x_0)$,  $\tan(\theta)$ is re expressed by $f'(x_0)$
            - $\displaystyle f'(x_0) = \frac{f(x_0)}{k}$
            - $\displaystyle k = \frac{f(x_0)}{f'(x_0)}$
          - $\begin{aligned} \displaystyle x_1 &= x_0 - k \\ &= x_0-\frac{f(x_0)}{f'(x_0)} \end{aligned}$
      




- **NHST for MLE**
  - Wald test 
  - Likelihood ratio 
  - Score statistic
  
  
- **Likelihood ratio test (Wilks test)**
  - **Concept**
    - Utilises the ratio of the likelihood of the sample data given the null hypothesised value of the parameter to the likelihood of the sample data given the observed value (the mle)
  - **The Likelihood Ratio statistic**
    - **Concept**
      - The ratio of the likelihood of the sample data given the null hypothesised value of the parameter to the likelihood of the sample data given sample estimate
    - **Mathematics**
      - $\displaystyle \Lambda =  \frac{\mathcal{L}{(\theta_0)}}{\mathcal{L}({\hat\theta})}$
        - ***Where***
          - $\mathcal{L}{(\theta_0)}$ - The likelihood of the sample data given the null hypothesised value of the parameter
          - $\mathcal{L}({\hat\theta})$ - The likelihood of the sample data given the sample estimate 
    - **Interpretation**
      - $\Lambda ‚â§ 1$
      - $\Lambda = 1$ indicates that the likelihood of the sample data given the null hypothesised value of the parameter is the same as the likelihood of the sample data given the observed value (the mle), which means that there is no difference between the observed estimate and the null hypothesised value 
      - The smaller the $\Lambda$ relative to 1, the further away the likelihood graph is from the null hypothesised value of the parameter on the parameter space 
  - **Wilk's statistic**
    - **Concept**
      - The Wilk's statistic is a log-transformed likelihood ratio statistic
      - The Likelihood ratio statistic is transformed to this Wilk's statistic so that, under certain regularity conditions, the Wilk's statistic has an asymptotic chi-squared distribution
      - It is often referred to 2ll because of how it looks in the mathematical expression
    - **Mathematics**
      - $\begin{aligned}\displaystyle -2\log \Lambda &= -2 \log\left[ \frac{\mathcal{L}{(\theta_0)}}{\mathcal{L}({\hat\theta})}\right] \\ &= -2\left[\log\mathcal{L}{(\theta_0)} - \log\mathcal{L}{(\hat\theta)}\right] \\ &= -2\left[\mathcal{l}{(\theta_0)} - \mathcal{l}{(\hat\theta)}\right]\end{aligned}$
    - **Distribution**  
      - **Concept**
        - Under the null hypothesis, the Wilk's statistic has an asymptotic chi-squared distribution with 1 degree of freedom 
      - **Mathematics**
        - $\displaystyle -2\log \Lambda \sim \chi^2(1)$
          - ***Notes***
            - Or it can be expressed as $\displaystyle -2\log \Lambda \xrightarrow{D} \chi^2(1)$
            - The df is the difference in the dimensions of the parameter spaces under $H_0 \cup H_1$ and $h_0$ (not sure what it means, but it's from Agresti)
 
- **Wald test (Wald, 1943)**
  - **Concept**
    - The Wald test or Wald statistic is somewhat like the idea of a z test or t test
  - **The Wald statistic**
    - **Mathematics**
      - $\displaystyle W = \frac{(\hat\theta - \theta_0)^2}{\sigma^2_{\theta}}$
        - ***Where***
          - $\hat\theta $ - The sample estimate 
          - $\theta_0$ - The value of the parameter under the null hypothesis 
          - $\sigma^2_{\theta}$ - The variance of the sample estimate under the alternative hypothesis - Under the theory of MLE, $\sigma_{\hat\theta}^2 = \frac{1}{nI(\hat\theta)}$
    - **Distribution**
      - **Concept**
        - The Wald statistic has an asymptotic/approximate central chi-squared distribution with 1 degree of freedom
      - **Mathematics**
        - $W \sim \chi^2(1)$
  - **z-transformed Wald statistic**
    - **Concept**
      - The Wald statistic transformed such that it has an asymptotic z normal distribution
    - **Mathematics**
      - $W_z = \sqrt{W}$
    - **Distribution**
      - **Concept**
        - The z Wald statistic has an asymptotic/approximate z normal distribution 
      - **Mathematics**
        - $W_z\sim \mathcal{N}$


- **Score statistic (Lagrange multiplier test)**
  - **The Score statistic**
    - **Concept**
      - The ratio of the square of the slope evaluated at the null hypothesised value of the parameter to the variance of the slope at the null hypothesised value of the parameter
    - **Mathematics**
      - $\displaystyle S =  \frac{\mathcal{l'}(\theta_0)^2}{nI(\theta_0)}$
        - ***Where***
          - $I(\theta_0)$ - The information at the null hypothesised value in the likelihood function - The variance of the slope of the likelihood function under the null hypothesis 
    - **Distribution**
      - **Concept**
        - Under the null hypothesis, the score statistic has an asymptotic chi-squared distribution with 1 degree of freedom
  - **The z-transformed Score statistic**
    - **Concept**
      - A transformed version of the Score statistic such that it has an asymptotic z normal distribution
      - The ratio of the slope evaluated at the null hypothesised value of the parameter to the standard deviation of the slope (which is equivalent to the expected curvature) at the null hypothesised value of the parameter - Because the expected curvature tells how much information is at the null hypothesised value of the parameter
    - **Mathematics**
      - $\displaystyle S_z = \sqrt{S} = \frac{\mathcal{l'}(\theta_0)}{\sqrt{nI(\theta_0)}}$
    - **Distribution**
      - **Concept**
        - Under the null hypothesis, the z-transformed Score statistic has an asymptotic z normal distribution

- **Evaluating the three tests**
  - The three tests are asymptotically equivalent (Cox and Hinkley, 1974, Sec. 9.3). For small to moderate sample sizes, the likelihood-ratio and score tests tend to be more reliable than the Wald test, that is that they have an actual error rate closer to the nominal level 
      

- **THINGS I WANT TO LEARN**
  - Law of large numbers 
  - Central Limit Theorem
  
  
  
  
  
  
  
  
  
      

- **Variance of model parameters**
  - **Concept**
    - The variance of a model parameter or the variance-covariance matrix of a vector of model parameters
    - Under regularity conditions, the variance-covariance of model parameters is the inverse of the information weighted by n (sample size) (Rao, 1973, p.364; Rao Cramer lower bound)
  - **Mathematics**
    - **For one parameter**
      - $\begin{aligned} \displaystyle \text{Var}(\hat\theta) &= \sigma_{\hat\theta}^{2}= \frac{1}{n}I^{-1}(\hat\theta) = \frac{1}{nI(\hat\theta)} \\ \displaystyle \text{SE}(\hat\theta) &= \sqrt{\sigma_{\hat\theta}^{2}} = \sqrt{\frac{1}{n}I^{-1}(\hat\theta)} = \sqrt{\frac{1}{nI(\hat\theta)}} \end{aligned}$
    - **For multiple parameters**
      - $\displaystyle \textbf{Cov}(\hat\theta) = \frac{1}{n}\textbf{I}^{-1}(\theta)$
        - ***Notes***
          - This is a variance-covariance matrix, the variance for each of the model parameters are in the diagonal. To get the Standard Error of each of the model parameters, square the variance of the model parameters. 
          
          

          
          
    


      
      
      
      

        
- **Maximum Likelihood Estimation for binomial Parameter**
  - **MLE for the population parameter**
    - **Concept**
      - The log likelihood of the kernal 
    - **Mathematics**
      - **The PMF of the binomial distribution**
        - $\displaystyle P(y) = {n\choose y} \pi^y (1 - \pi)^{n - y} ~~~, y = 0:n$
      - **The log likelihood function:**
        - $\begin{aligned} \displaystyle \mathcal{l}(\pi)&=\log{\left[\pi^{y}(1-\pi)^{n-y}\right]} \\ \displaystyle &= y\log(\pi)+(n-y)\log(1-\pi) \end{aligned}$ 
          - ***Notes***
            - Only the kernal of the PMF of the binomial distribution contains the parameters and relevant, therefore, only the kernal is used 
      - **The first derivative of the likelihood function:**
        - $\begin{aligned} \displaystyle \frac{\partial{\mathcal{l}(\pi)}}{\partial{\pi}} \displaystyle &= \frac{y}{\pi} - \frac{n - y}{1- \pi} \\ \displaystyle &= \frac{y - n\pi}{\pi(1-\pi)} \end{aligned}$
      - **Maximisation problem: set the derivative of the log likelihood function to 0 and find $\pi$ (the estimating equation)**
        - $\begin{aligned} \displaystyle \frac{y - n\pi}{\pi(1-\pi)} &= 0 \\ \displaystyle y - n\pi &= 0 \\ \displaystyle \hat\pi &= \frac{y}{n}\end{aligned}$
          - ***Notes***
            - As you can see, this is the sample proportion of success for the $n$ trials - This is the MLE of the population probability
  - **Information**
    - **Mathematics**
      - $\displaystyle I_{\pi} =-E\left(\frac{\partial^2 f}{\partial \pi^2}\right) = E\left[ \frac{y}{\pi^2} - \frac{n-y}{(1-\pi)^2}\right] = \frac{n}{\pi(1-\pi)}$
  - **Variance of $\hat\pi$**
    - **Concept**
      - The variance of the parameter estimate in the distribution under the null hypothesis based on the ML method 
      - It is estimated from the variance of the sample 
    - **Mathematics**
      - $\begin{aligned} \displaystyle \sigma_{\hat\pi}^{2} &= I^{-1} \\ \displaystyle \sigma_{\hat\pi}^{2} &= -E\left(\frac{\partial^2 f}{\partial \pi^2}\right)^{-1} \\ \displaystyle &= E \left[ \frac{y}{\pi^2} + \frac{n-y}{(1-\pi)^2} \right]^{-1} \\ \displaystyle &= \left[\frac{n}{\pi(1 - \pi)}\right]^{-1} \\ \displaystyle &= \frac{\pi(1-\pi)}{n} \end{aligned}$
  - **Standard error**
    - **Mathematics**
      - $\begin{aligned} \displaystyle \sigma_{\hat\pi} &= \sqrt{\sigma_{\hat\pi}^{2}} \\ &= \sqrt{\frac{\pi(1-\pi)}{n}} \end{aligned}$
  - **Confidence Interval (Not yet developed)**
    - **Wald confidence interval**
      - **Concept**
        - The Wald confidence interval uses the normal approximation
      - **Mathematics**
        - $CI = \hat\pi ¬± z_{1-\frac{\alpha}{2}} \times \sigma_{\hat\pi}$
  - **Others**
    - A marked divergence in results of Wald and Likelihood ratio inference indicates that the distribution of the parameter may not be close to normality 
    
- **NHST of the binomial parameter $\hat\pi$**
  - **Wald test**
    - **The z Wald statistic**
     - **Mathematics**    
      - $\displaystyle z_W = \frac{\hat\pi - \pi_0}{\sigma_{\hat\pi}} = \frac{\hat\pi - \pi_0}{\sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}}$
  - **Score statistic test**
    - **Concept**
      - Since the Wald statistic uses the standard error evaluated at $\hat\pi$ and the score statistic uses the standard error evaluated at $\pi_0$, the score statistic is preferred because it uses the actual null SE rather than an estimate of the null SE
    - **The score statistic**
      - **Mathematics**
        - $\displaystyle \frac{ \mathcal{l}(\theta_0)^2}{I(\theta_0)} = \displaystyle \frac{ \mathcal{l}(\pi_0)^2}{I(\pi_0)} $
        - Finding the slope of the likelihood function at the null hypothesised value of the parameter ($S(\pi_0)^2$)
          - The first derivative of the likelihood function for $\pi$
            - $\displaystyle \mathcal{l}(\pi) = \frac{y - n\pi}{\pi(1-\pi)}$
          - Sub in $\pi_0$
            - $\displaystyle S(\pi_0) = \frac{y - n\pi_0}{\pi_0(1-\pi_0)}$
          - Square it 
            - $\displaystyle \left[\frac{y - n\pi_0}{\pi_0(1-\pi_0)}\right]^2 $
        - Finding the SE of the slope under the null hypothesis ($I(\pi_0)$)
          - $\begin{aligned}\displaystyle I(\pi_0) &=  -E\left(\frac{\partial{}^2f}{\partial{x_{1}^{2}}}\right) \\ \displaystyle &= -E\left(\frac{\partial{}^2 \mathcal{L}(\pi)}{\partial{\pi_0^{2}}}\right) \\ \displaystyle &= \frac{n}{\pi_0 (1 - \pi_0)} \end{aligned}$
        - Hence 
          - $\displaystyle \frac{S(\pi_0)^2}{I(\pi_0)} = \frac{\left[\frac{y - n\pi_0}{\pi_0(1-\pi_0)}\right]^2}{\frac{n}{\pi_0 (1 - \pi_0)}} = \frac{(y - n\pi_0)^2}{\frac{\pi_0(1-\pi_0)}{n}} = \frac{(\hat\pi - \pi_0)^2}{\frac{\pi_0(1-\pi_0)}{n}}$
        



- **Continuity correction**
  - **Concept**
    - A correction made when a discrete distribution is approximated by a continuous distribution













<p style = "margin-bottom: 0px; font-size: 20px; ">**The Generalised Linear Model**</p>      

- **Concept**
  - An extension of ordinary regression models to encompass non-normal distributions of the outcome variable/residuals 
  - There three components of GLM 
    - Random component
    - Systematic component 
    - Link function
  - Random component 
    - Identifies the outcome variable and its probability distribution
  - Systematic component 
    - Specifies explanatory variables used in a linear combination

- **Link function**
  - A function in Generalised Linear Models that maps the random with the systematic components
  - **Types of link function**
    - Identity link function
    - Logit link function
    - 
    - 


<p style = "margin-bottom: 0px; font-size: 20px; ">**Other stuff**</p>    

- **Unbiasedness of an estimator**
  - **Definition**
    - Let $x_1, x_2, x_3, \cdots , x_n$ be a sample on a random variable $X$ with pdf $f(x; \theta)$. Let $S = S(x_1, x_2, x_3, \cdots , x_n)$ be a statistic. $S$ is an unbiased estimator of the population parameter $\theta$ if $E(S) = \theta$






- **Cram√©r-Rao Lower Bound**
  - **Concept**
    - The CRLB states that the variance of an estimator cannot be lower than the CRLB
    - That is, the CRLB is the minimum variance of an estimator 
  - **For unbiased or biased estimators**
    - **Mathematics**
      - This is for the case when $\hat\theta$ can be an unbiased or biased estimator of $\theta$, that is when the expectation of $\hat\theta$ is not $\theta$ but some kind of function of this (e.g. $k(\theta)$)
      - Let $x_1, x_2, x_3, \cdots, x_n$ be idd with a pdf $f(x; \theta)$. Let $S = u(x_1, x_2, x_3, \cdots, x_n)$ be a sample statistic with a mean $E(S) = E[u(x_1, x_2, x_3, \cdots, x_n)] = k(\theta)$. Under the first 4 regularity conditions: 
        - $\displaystyle \text{Var}(\theta) ‚â• \frac{\left[k'(\theta)\right]^2}{n I(\theta)}$
    - **Proof**
      - **Scenario**
        - Let $\hat\theta = u(X) = u(x_1, x_2, \cdots , x_n)$ be a sample statistic and an estimator of the true value of the parameter $\theta$. 
        - To generalise the proof to accommodate both unbiased and biased estimator, let's assume that $\hat\theta$ can be a biased or unbiased estimator, hence, let's express the expectation of $\hat\theta$ as $\text{E}(\hat\theta) = g(\theta)$ (So that if $\hat\theta$ is an unbiased estimator, $g()$ would be an identity function). 
        - Let $f(x; \theta)$ be the pdf of the random variable $X$
        - **The log-likelihood function**
          - $\mathcal{l}(\theta; X)$
        - **The score**
          - $\begin{aligned}\displaystyle S &= \frac{\partial \log \mathcal{f}(x; \theta) }{\partial \theta} \\ &= \frac{1}{f(x; \theta)} \times \frac{\partial f(x; \theta)}{\partial \theta} \\ &= \frac{\partial f(x; \theta)}{\partial \theta f(x; \theta)}\end{aligned}$
      - **Covariance of $S$ and $\hat\theta$**
        - $\displaystyle \text{Cov}(S, \hat\theta) = \text{E}\left[ (S - \text{E}(S)) (\hat\theta - \text{E}(\hat\theta))\right]=\text{E}(S\hat\theta) - \text{E}(S)\text{E}(\hat\theta)$
          - ***Notes***
            - The definition of the covariance of 2 random variables is: 
              - $\displaystyle \text{Cov}(X, Y) = \text{E}\left[ (X - \text{E}(X)) (Y - \text{E}(Y))\right]=\text{E}(XY) - \text{E}(X)\text{E}(Y)$
        - Since $\text{E}(S) = 0$ (proof is in the Score section), the covariance simplifies to: 
        - $\displaystyle \text{Cov}(S, \hat\theta) =\text{E}(S\hat\theta)$
      - **Expanding the expression**
        - $\begin{aligned}\displaystyle \text{Cov}(S, \hat\theta) &= \text{E}(S\hat\theta) \\ &= \text{E}\left[ \left( \frac{\partial f(X; \theta)}{\partial \theta f(X; \theta)}\right)  \hat\theta\right]\end{aligned}$
      - **Expressing it as an integral**
        - $\begin{aligned} \displaystyle \text{Cov}\left( S, T\right) &= \text{E}\left[ \left( \frac{\partial f(x; \theta)}{\partial \theta f(X; \theta)}\right) \hat\theta\right] \\ &= \int_{}^{}{\frac{\partial f(x; \theta)}{\partial \theta f(X; \theta)}  u(x) f(x; \theta) ~ dx} \\ &= \frac{\partial}{\partial \theta}\int_{}^{}{\frac{f(x; \theta)}{f(x; \theta)}u(x) f(x; \theta) ~ dx} \\ &= \frac{\partial}{\partial \theta}\int_{}^{}{u(x) f(x; \theta) ~ dx} \\ &= \frac{\partial}{\partial \theta}\text{E}(\hat\theta) \\ &= g'(\theta) \end{aligned}$ 
      - **Since The Cauchy-Schwarz inequality proofed that**
        - $\sqrt{\text{Var}(X) \text{Var}(Y)} ‚â• |\text{Cov(X, Y)}|$
      - **And as proofed, $\text{Cov(X, Y)} = g'(\theta)$**
      - **Therefore** 
        - $\begin{aligned} \displaystyle \sqrt{\text{Var}(S) \text{Var}(\hat\theta)} &‚â• |g'(\theta)| \\  \text{Var}(S)\text{Var}(\hat\theta) &‚â• \left[g'(\theta)\right]^2 \\ \text{Var}(\hat\theta) &‚â• \frac{\left[g'(\theta)\right]^2 }{\text{Var}(S)} \\ \text{Var}(\hat\theta) &‚â• \frac{\left[g'(\theta)\right]^2 }{nI(\theta)}\end{aligned}$
  - **For unbiased estimators**  
    - **Mathematics**
      - If $S = u(x_1, x_2, x_3, \cdots, x_n)$ is an unbiased estimator of $\theta$, so that $k(\theta) = \theta$, then the Cram√©r-Rao inequality becomes: 
      - $\displaystyle \text{Var}(\hat\theta) ‚â• \frac{1}{I(\theta)}$
    

- **Efficiency**
  - **Concept**
    - The efficiency of an estimator describes quality of an unbiased estimator through the variability of unbiased estimates around the true population parameter (this indicates the deviance between the estimator and the true population parameter)
  - **Efficient Estimator**
    - **Concept**
      - A sample statistic is an efficient estimator of the population parameter $\theta$ only if the variance of the sample statistic is equal to the Cram√©r-Rao lower bound (hence it has the minimum variance)
- **Efficiency**
    - The efficiency of an estimator is quantified as the ratio of the Cram√©r-Rao lower bound to the actual variance of any unbiased estimator 
  - **Mathematics**
    - $\displaystyle \text{Efficiency} = \frac{\textit{CRLB}}{\text{Var}(\theta)} \\ \displaystyle e(\hat\theta_{1n}) = \frac{\frac{1}{I(\theta_0)}}{\sigma^2_{\hat\theta_{1n}}}$
  - **Interpretation**
    - According to the CRLB, the variance cannot be lower than the CRLB
    - Hence, efficiency ranges from asymptotic 0 to 1
    - An efficiency of 1 means that the estimator is asymptotically efficient 
    - An efficiency smaller than 1 means that the estimator is inefficient 
    - The smaller the efficiency below 1 and towards 0, the less efficient is the estimator
- **MLE and normality and efficiency**
  - **Concept**
    - It can be shown that under regularity conditions, mles are asymptotically normal and efficient. In other words, as sample size increases towards infinity, the distribution of any mles approaches normal and the efficiency approaches 1 (the variances of mles approaches the CRLB) 
  - **Proof**
    - Proof not shown
    - Proof is available in Maximum Likelihood Methods in Introduction to Mathematical Statistics (Hogg and McKean)
  
  

  
- **Asymptotic Relative Efficiency (ARE)**
  - **Concept**
    - The asymptotic relative efficiency between two unbiased and asymptotically normal estimators
    - Compares the efficiency between two unbiased and asymptotically normal estimators
  - **Mathematics**
    - The asymptotic relative efficiency of an asymptotically normal and unbiased estimator $\hat\theta_{1n}$ to another another asymptotically normal and unbiased estimator $\hat\theta_{2n}$ is the reciprocal of the ratio of their respective asymptotic variances  
    - $\displaystyle e\left(\hat\theta_{1n}, \hat\theta_{2n} \right) = \frac{\sigma^2_{\hat\theta_{2n}}}{\sigma^2_{\hat\theta_{1n}}}$
  - **Interpretation**
    - If two estimators are asymptotially normal with the same asymptotic mea, then the estimator with the smaller asymptotic variance should be selected over the other as a better estimator 
  - 

- **Regularity conditions of MLEs (DON'T FUCKING KNOW! Not developed)**
  1. The variables are independent and identically distributed with density $f(y; \theta)$
  2. The parameter space $\Theta$ is compact
  3. The value of the parameter is identified 
  4. The likelihood function is continuous in $\theta$
  5. $E_{\theta_0} \log f(Y; \theta)$ exists
  6. The log-likelihood function is such that $\frac{1}{n}\mathcal{L}(y; \theta)$ converges in probability to $E_{\theta_0} \log f(Y; \theta)$ uniformly in $\theta \in \Theta$
  7. The pdf is at least twice differentiable as a function of $\theta$
  8. Integration and differential operators are interchangeable - The order of integration and differentiation can be interchanged 
  9. The information matrix exists and is non-singular 
  10. The integral $\int f(x; \theta) dx$ can be differentiated twice under the integral sign as a function of $\theta$
- **Additional regularity conditions**
  - The pdf is at least three times differentiable as a function of $\theta$. For all $\theta \in \Omega$, there exist a constant c and a function $M(x)$ such that 
  
  
  
- **Properties of MLEs**
  - MLEs are asymptotically efficient 
  - MLEs are asymptotically normal 
  - MLEs are asymptotically consistent 
  
  
- **MLEs are asymptotically efficient**
  - **Concept**
    - Under regularity conditions, MLEs are asymptotically efficient
    - This means that the variance of an mle approaches the minimum variance (i.e. CRLB) as sample size increases towards infinity
    - The efficiency of mles converges to 1 as $n \rightarrow \infty$
    
    
- **MLEs are asymptotically normal**
  - **Concept**
    - Under certain regularity conditions and correct model specification, MLEs are asymptotically normal 
    - The distribution of $\hat\theta_{mle}$ approaches normal as sample size increases towards infinity 
    


- **MLEs are asymptotically consistent**
  - **Concept**
    - Under regularity conditions 1-6, MLEs are asymptotically consistent 
    - This means that MLEs in the sampling distribution converge in probability to the true value of the parameter as sample size increases towards infinity 
    - $\hat\theta \overset{P}{\to} \theta_0 $



- **Variance of an MLE**    
  - **Concept**
    - The asymptotically consistent estimate of the variance 
  - **Mathematics**
    - $\displaystyle \text{Var}(\hat\theta) = \frac{1}{nI(\theta_0)}$
  - **Estimation**
    - **Concept**
      - As seen, the variance of an MLE is a function of the true population parameter value. However, this is often unknown, the estimate of this value is used instead. 
    - **Mathematics**
      - $\displaystyle \text{Var}(\hat\theta) = \frac{1}{nI(\hat\theta)}$
    - **Asymptotically consistent**
      - This estimate of the variance is asymptotically consistent 
      - It converges in probability to the true variance 
      - $I(\hat\theta)  \overset{P}{\to} I(\theta_0) $

- **SE of an MLE**
  - **Mathematics**
    - $\displaystyle \sqrt{\frac{1}{nI(\theta_0)}}$
  - **Estimation**
    - **Mathematics**
      - $\displaystyle \sqrt{\frac{1}{nI(\hat\theta)}}$


##########
OTHERS 

- **Negative Binomial Distribution**
  - **Concept**
    - 
        

- **Terms**
  - Complement of an event - The complement of an event is the probability of that event not occurring 
        





**Others**

 - **Score**
      - **Mathematics**
        - **The likelihood function**
          - $\displaystyle \mathcal{L}\left( \theta; x \right) = \prod_{i = 1}^{n = 3}{f(x_i; \theta)} = f(x_1; \theta) \times f(x_2; \theta) \times f(x_3; \theta)$
        - **The log likelihood**
          - $\begin{aligned} \displaystyle \mathcal{l}(\theta; \textbf{x}) &= \log \mathcal{L}\left( \theta; \textbf{x} \right) \\ &= \log \prod_{i = 1}^{n = 3}{f(x_i; \theta)} \\ &= \log{\left[f(x_1; \theta) \times f(x_2; \theta) \times f(x_3; \theta)\right]} \\ &= \log{f(x_1; \theta)} + \log{f(x_2; \theta)} + \log{f(x_3; \theta)} \end{aligned}$
            - ***Notes***
              - The log of the product is sum of the log of each factor in the product
        - **The score (the first derivative of the log likelihood)**
          - $\begin{aligned} \displaystyle S &=  \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}  \\ &= \frac{\partial}{\partial\theta}\left[ \log{f(x_1; \theta)} + \log{f(x_2; \theta)} + \log{f(x_3; \theta)} \right] \\ &= \frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta} \end{aligned}$
            - ***Notes***
              - The derivative of a sum is the sum of the derivative of each of the elements in the sum
    - **The expectation of the score**
      - **Mathematics**
        - $\begin{aligned} \displaystyle E\left(S \right) &= E\left[\frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ &= E\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &= E\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + E\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ E\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \end{aligned}$
          - ***Notes***
            - The expectation of a sum is the sum of the expectation of  each of the elements in the sum
      - **The expectation of the score is 0**
        - Since any one of the expectations is 0 (as shown in the one-observation case), the sum of all the expectations is also 0
    - **The variance of the score**
      - **Mathematics**
        - **Variance defined as the second moment about the mean**
          - $\begin{aligned} \displaystyle \text{Var}(S) &= \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right] \\ \displaystyle &= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_2; \theta)}}{\partial \theta} + \frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + \text{Var}\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ \text{Var}\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] + 2\sum_{j = 1}^{n = 3}{\sum_{i = 1}^{n = 3}{\text{Cov}\left(\frac{\partial \log{f(x_i; \theta)}}{\partial \theta}, \frac{\partial \log{f(x_j; \theta)}}{\partial \theta}\right)}} \end{aligned}$
          - Assuming that observations are uncorrelated: 
          - $\begin{aligned} \displaystyle \text{Var}(S) &= \text{Var}\left[\frac{\partial \log{f(x_1; \theta)}}{\partial \theta}\right] + \text{Var}\left[\frac{\partial \log{f(x_2; \theta)}}{\partial \theta}\right]+ \text{Var}\left[\frac{\partial \log{f(x_3; \theta)}}{\partial \theta}\right] \\ &= 3\times \text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ &= n\times\text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right]\end{aligned}$
    - **Fisher Information**
      - **Concept**
        - The Information from a sample with 3 observations is 3 times the Information from any single observation
      - **Mathematics**
        - $\displaystyle \text{Var}(S) = \text{Var}\left[ \frac{\partial \mathcal{l}(\theta; \textbf{x})}{\partial \theta}\right]$
        - $\begin{aligned}I_3(\theta) &= 3 \times \text{Var}\left[\frac{\partial \log{f(x; \theta)}}{\partial \theta}\right] \\ I_3(\theta) &= 3 I_1(\theta)\end{aligned}$
        
        
  - **The expectation of the score**
    - **Concept**
      - Under certain regularity conditions, the expectation of the score evaluated at the true value of $\theta$ is 0
      - Imagine you know the true value of the parameter, you then take many samples, each time you take a sample, you calculate the score with respect to the true value of the parameter, after doing this for each of the samples, you will have many scores, each coming from each sample, the mean of these scores will be 0, that is, they are clustered around 0
    - **Mathematics**
      - $\displaystyle E(S)  = E\left( \frac{\partial f(x_i; \theta)}{\partial \theta}\right) = 0$
    - **Proof that the expectation of the score is 0**
        - **Begin with the identity**
          - $\displaystyle 1 = \int_{-\infty}^{\infty}{\mathcal{L}(\theta; x)} ~  ~ dx = \int_{-\infty}^{\infty}{\mathcal{f}(x; \theta)}  ~ dx$
        - **The first derivative under the integral sign**
          - $\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta}}  ~ dx$
        - **Which can be reexpressed as** 
          - $\displaystyle 0 = \int_{-\infty}^{\infty}{\frac{\partial\mathcal{f}(x; \theta)}{\partial \theta \mathcal{f}(x; \theta)}\mathcal{f}(x; \theta)} ~ dx = \int_{-\infty}^{\infty}{\frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\mathcal{f}(x; \theta)} ~ dx = E\left[ \frac{\partial \log \mathcal{f}(x; \theta)}{\partial \theta}\right]$







































